import streamlit as st
from io import BytesIO
import pandas as pd
import time
import altair as alt
import re, io
from typing import Tuple
import collections.abc as abc
import numpy as np
import unicodedata, re
import streamlit_authenticator as stauth
st.set_page_config(page_title="å£²ä¸Šãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰", layout="wide")
def to_dict(obj):
    """Mapping ã‚’å†å¸°çš„ã«æ™®é€šã® dict ã¸"""
    if isinstance(obj, abc.Mapping):
        return {k: to_dict(v) for k, v in obj.items()}
    return obj

# â”€â”€â”€ èªè¨¼ â”€â”€â”€
# èªè¨¼ãƒ–ãƒ­ãƒƒã‚¯ã‚’æ›¸ãæ›ãˆ
if "auth_ok" not in st.session_state:
    credentials = to_dict(st.secrets["credentials"])   # â† ãã®ã¾ã¾

    authenticator = stauth.Authenticate(
        credentials, "salesdash", "salesdash_key", cookie_expiry_days=7
    )

    # â˜… v0.4 ä»¥é™ã® login â˜…
    fields = {
        "Form name": "ãƒ­ã‚°ã‚¤ãƒ³",
        "Username": "ãƒ¦ãƒ¼ã‚¶ãƒ¼å",
        "Password": "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰",
        "Login": "ãƒ­ã‚°ã‚¤ãƒ³"
    }
    name, auth_status, username = authenticator.login(
        fields=fields,       # â† ã“ã“ãŒå¿…é ˆ
        location="main"
    )

    if not auth_status:
        st.stop()

# â˜…â˜… â‘¡ ãƒ­ã‚°ã‚¢ã‚¦ãƒˆç›´å¾Œã«ãƒ•ãƒ©ã‚°ã‚’æ¶ˆã™ãªã‚‰ â†“ ã‚’è¿½åŠ  â˜…â˜…
authenticator.logout("ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ", "sidebar")
st.session_state.pop("auth_ok", None)     # â† è¿½åŠ 

# ã¾ãšã¯åˆ†ã‹ã£ã¦ã„ã‚‹åˆ¥åã‚’ã“ã“ã«è¿½åŠ ã—ã¦ã„ã

# ========= åº—èˆ—åã‚¨ã‚¤ãƒªã‚¢ã‚¹ã®å¤–éƒ¨èª­è¾¼ =========
import os, json, pathlib
import streamlit as st

# YAML ã¯ä»»æ„ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã§ YAML ã‚’ä½¿ã†å ´åˆã®ã¿å¿…è¦ï¼‰
try:
    import yaml
except Exception:
    yaml = None

# TOML èª­ã¿ã¯ã€Œä»»æ„ã€ï¼šå¤–éƒ¨ TOML ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã‚€ã¨ãã ã‘ä½¿ã†
# secrets.toml ã¯ streamlit ãŒ st.secrets ã§èª­ã‚“ã§ãã‚Œã‚‹ã®ã§ tomllib ã¯ä¸è¦
try:
    import tomllib  # Python 3.11+
except Exception:
    tomllib = None


@st.cache_data(show_spinner=False)
def load_store_aliases() -> dict[str, str]:
    """
    åº—èˆ—ã‚¨ã‚¤ãƒªã‚¢ã‚¹ã‚’å¤–éƒ¨ã‹ã‚‰èª­ã¿è¾¼ã‚€ã€‚
    å„ªå…ˆé †ä½: st.secrets["store_aliases"] > ç’°å¢ƒå¤‰æ•° STORE_ALIASES_FILE > æ—¢å®šãƒ‘ã‚¹
    ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: YAML / JSON / TOMLï¼ˆæ‹¡å¼µå­ã§è‡ªå‹•åˆ¤åˆ¥ï¼‰
    """
    # 1) secretsï¼ˆæœ¬ç•ªã§ã®ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰åŒæ§˜ã®ç®¡ç†ï¼‰
    if "store_aliases" in st.secrets:
        # secrets.toml ã® [store_aliases] ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ dict ã«
        try:
            data = dict(st.secrets["store_aliases"])
            return {str(k): str(v) for k, v in data.items()}
        except Exception:
            pass

    # 2) ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹æŒ‡å®šï¼ˆç’°å¢ƒå¤‰æ•°ï¼‰
    path = os.environ.get("STORE_ALIASES_FILE")
    # 3) æ—¢å®šã®æ¤œç´¢ãƒ‘ã‚¹ï¼ˆå­˜åœ¨ã™ã‚‹æœ€åˆã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¡ç”¨ï¼‰
    candidate_paths = [
        path,
        "config/store_aliases.yaml",
        "config/store_aliases.yml",
        "config/store_aliases.json",
        "config/store_aliases.toml",
        ".streamlit/store_aliases.toml",
    ]
    for p in candidate_paths:
        if not p:
            continue
        p = pathlib.Path(p)
        if not p.exists():
            continue
        try:
            ext = p.suffix.lower()
            with p.open("rb") as f:
                if ext in (".yml", ".yaml") and yaml is not None:
                    data = yaml.safe_load(f) or {}
                elif ext == ".json":
                    data = json.load(f) or {}
                elif ext == ".toml":
                    if tomllib is None:
                        data = {}  # tomllib ãŒç„¡ã‘ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—
                    else:
                        t = tomllib.load(f) or {}
                        data = t.get("store_aliases", t)
                else:
                    data = {}
            if isinstance(data, dict):
                return {str(k): str(v) for k, v in data.items()}
        except Exception:
            # å£Šã‚Œã¦ã„ã¦ã‚‚è½ã¨ã•ãšã‚¹ã‚­ãƒƒãƒ—
            continue

    # 4) è¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã°ç©º
    return {}


STORE_ALIASES: dict[str, str] = load_store_aliases()


import hashlib
from io import BytesIO
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
def months_for_store_year(store: str, year: int,
                          sales_df: pd.DataFrame | None,
                          yj_df: pd.DataFrame | None,
                          pp_df: pd.DataFrame | None) -> list[int]:
    """åº—èˆ—Ã—å¹´ã«å¯¾ã—ã¦ã€sales_df / yj_df / pp_df ã®ã„ãšã‚Œã‹ã«
    æœˆãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹æœˆã‚’åˆé›†åˆã§è¿”ã™ï¼ˆæ˜‡é †ï¼‰ã€‚"""

    def _pick(df):
        if df is None or df.empty:
            return set()
        cols = df.columns
        # å¿…è¦ã‚«ãƒ©ãƒ ãŒãã‚ã£ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã ã‘å¯¾è±¡
        if not {"åº—èˆ—å", "å¹´", "æœˆ"}.issubset(cols):
            return set()
        sub = df[(df["åº—èˆ—å"] == store) &
                 (pd.to_numeric(df["å¹´"], errors="coerce") == int(year))]
        if sub.empty:
            return set()
        return set(pd.to_numeric(sub["æœˆ"], errors="coerce")
                   .dropna().astype(int).unique().tolist())

    months = _pick(sales_df) | _pick(yj_df) | _pick(pp_df)
    return sorted(m for m in months if 1 <= m <= 12)
def safe_year_month_for_sales(sel_year, sel_month, sales_df=None):
    """
    å£²ä¸Šãƒ•ã‚¡ã‚¤ãƒ«ãŒæœªèª­è¾¼ã§ã‚‚å¹´ãƒ»æœˆã‚’å®‰å…¨ã«è¿”ã™ã€‚
    sales_df ãŒã‚ã‚Œã°ã€æœ€æ–°ã®å¹´ã‚’å„ªå…ˆã—ã€æœˆã¯é¸æŠå€¤ãŒãªã‘ã‚Œã°æœ€å¤§æœˆã€‚
    sales_df ãŒç„¡ã‘ã‚Œã°ã€é¸æŠå€¤â†’ãªã‘ã‚Œã°ä»Šæ—¥ã®å¹´ãƒ»æœˆã€‚
    """
    try:
        if sales_df is not None and not sales_df.empty:
            latest = int(pd.to_numeric(sales_df["å¹´"], errors="coerce").max())
            # æœˆã®å€™è£œï¼ˆãã®å¹´ã«å­˜åœ¨ã™ã‚‹æœˆï¼‰
            m_opts = sorted(pd.to_numeric(
                sales_df.query("å¹´ == @latest")["æœˆ"], errors="coerce"
            ).dropna().astype(int).unique().tolist())
            if not m_opts:
                return int(sel_year) if sel_year else datetime.now().year, \
                       int(sel_month) if sel_month else datetime.now().month
            # sel_month ãŒå€™è£œã«ãªã„/None ã®å ´åˆã¯æœ€å¤§æœˆã‚’æ¡ç”¨
            mm = int(sel_month) if sel_month and int(sel_month) in m_opts else m_opts[-1]
            return latest, mm
    except Exception:
        pass

    # sales_df ãŒç„¡ã„ or å–å¾—ã«å¤±æ•— â†’ ã‚»ãƒ¬ã‚¯ã‚¿å€¤ or ä»Šæ—¥
    y = int(sel_year) if sel_year else datetime.now().year
    m = int(sel_month) if sel_month else datetime.now().month
    return y, m
def _blob(up):
    """UploadedFile -> (bytes, name)"""
    data = up.getvalue() if hasattr(up, "getvalue") else (up.seek(0) or up.read())
    if not isinstance(data, (bytes, bytearray)):
        data = b""
    return data, getattr(up, "name", "noname.xlsx")

@st.cache_data(show_spinner=False)
def parse_sales_cached(blob: bytes, name: str):
    """å£²ä¸Šç®¡ç†ï¼š1ãƒ•ã‚¡ã‚¤ãƒ«åˆ†ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ã§è§£æ"""
    b = BytesIO(blob)
    df = read_sales_sheet(b)
    y, m = infer_year_month(df)
    store = _store_from_filename(name)

    b.seek(0); ltv  = parse_ltv(b)
    b.seek(0); card = parse_card_count(b)

    agg = {
        "ç·å£²ä¸Š": pd.to_numeric(df["ç·å£²ä¸Š"], errors="coerce").sum(),
        "ç·æ¥é™¢æ•°": pd.to_numeric(df["ç·æ¥é™¢æ•°"], errors="coerce").sum(),
        "ä¿é™ºæ–°æ‚£": pd.to_numeric(df["ä¿é™ºæ–°æ‚£"], errors="coerce").sum(),
        "è‡ªç”±æ–°æ‚£": pd.to_numeric(df["è‡ªç”±æ–°æ‚£"], errors="coerce").sum(),
    }
    return {"store":store, "year":y, "month":m, "agg":agg, "ltv":ltv, "card":card}

@st.cache_data(show_spinner=False)
def parse_yj_cached(blob: bytes, name: str):
    """äºˆå®Ÿï¼š1ãƒ–ãƒƒã‚¯åˆ†ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ã§è§£æ"""
    df = _yj_parse_with_sheet_progress(BytesIO(blob))
    if df is None or df.empty: 
        return pd.DataFrame()
    df = df.copy()
    df["å…ƒãƒ•ã‚¡ã‚¤ãƒ«"] = name
    return df

@st.cache_data(show_spinner=False)
def parse_person_cached(blob: bytes, name: str):
    """å€‹äººç”Ÿç”£æ€§ï¼š1ãƒ–ãƒƒã‚¯åˆ†ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ã§è§£æ"""
    df, _logs = parse_person_book(BytesIO(blob), name)
    return df if df is not None else pd.DataFrame()

def _parallel_map(func, files):
    """ä¸¦åˆ—è§£æï¼ˆãƒ•ã‚¡ã‚¤ãƒ«æ•°ãŒå¤šã„æ™‚ã«æœ‰åŠ¹ï¼‰"""
    with ThreadPoolExecutor(max_workers=min(8, len(files))) as ex:
        futs = [ex.submit(func, *_blob(up)) for up in files]
        for fu in as_completed(futs):
            yield fu.result()
def _norm_store_core(s: str) -> str:
    """ãƒ•ã‚¡ã‚¤ãƒ«å/è¡¨è¨˜ã®æºã‚Œã‚’å¸åã—ã¦åº—åã®ã‚³ã‚¢ã‚’å–ã‚Šå‡ºã™"""
    s = unicodedata.normalize("NFKC", str(s))
    s = s.strip()
    s = re.sub(r"\.xlsx$", "", s, flags=re.I)    # æ‹¡å¼µå­
    s = re.sub(r"^\d+[._\-\s]*", "", s)          # å…ˆé ­ã®ç•ªå·
    s = re.sub(r"\s+", "", s)                    # ç©ºç™½
    s = re.sub(r"\(.*?\)|ï¼ˆ.*?ï¼‰", "", s)         # ã‚«ãƒƒã‚³å†…
    s = re.sub(r"\d{1,2}æœˆ.*$", "", s)           # ã€Œ1æœˆâ€¦ã€ãªã©
    # ä½™è¨ˆãªèªã‚’é™¤å»
    s = s.replace("æ ªå¼ä¼šç¤¾","").replace("æœ‰é™ä¼šç¤¾","")
    s = s.replace("åº—","").replace("é™¢","").replace("æ”¯åº—","").replace("æœ¬åº—","")
    s = re.sub(r"(ã‚¤ãƒ¼ã‚°ãƒ«|ã‚¯ãƒ¬ãƒ¼ãƒ³|EAGLE|ï½…ï½ï½‡ï½Œï½…|ï¼¹ï¼´|YT|ï¼¹ï¼¢|YB)", "", s, flags=re.I)
    return s

def canonical_store_name(raw: str) -> str:
    core = _norm_store_core(raw)
    if core in STORE_ALIASES:
        return STORE_ALIASES[core]
    # æœªç™»éŒ²ã¯ã€Œã‚¤ãƒ¼ã‚°ãƒ«ï¼‹ã‚³ã‚¢ã€ã«å¯„ã›ã‚‹
    return ("ã‚¤ãƒ¼ã‚°ãƒ«" + core) if core else "ã‚¤ãƒ¼ã‚°ãƒ«ä¸æ˜"

def unify_store_names(df: pd.DataFrame, col="åº—èˆ—å") -> pd.DataFrame:
    if col in df.columns:
        out = df.copy()
        out[col] = out[col].apply(canonical_store_name)
        return out
    return df



# ------------------ ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ------------------

def _num(s):
    if s is None:
        return None
    if isinstance(s, (int, float)):
        return float(s)
    s = str(s)
    s = re.sub(r"[â–²â–³âˆ’\-]", "-", s)
    s = re.sub(r"[^\d\.\-]", "", s)
    try:
        return float(s) if s != "" else None
    except Exception:
        return None
def _metric_card(col, label, cur, prv, unit=""):
    """st.metric ç”¨ã®ãƒ©ãƒƒãƒ‘ãƒ¼ï¼ˆå‰å¹´æ¯”%ã‚’è‡ªå‹•è¨ˆç®—/å®‰å…¨åŒ–ï¼‰ã€‚"""
    import math
    cur_txt = "-" if cur is None or (isinstance(cur, float) and math.isnan(cur)) else f"{int(round(cur)):,}{unit}"
    delta_txt = ""
    if (prv is not None) and (not (isinstance(prv, float) and math.isnan(prv))) and prv != 0:
        delta = (cur - prv) / prv * 100 if (cur is not None and not (isinstance(cur, float) and math.isnan(cur))) else 0.0
        delta_txt = f"{delta:+.1f}% vs å‰å¹´åŒæœˆ"
    with col:
        st.metric(label, cur_txt, delta_txt)

def fmt_comma_int(df: pd.DataFrame, cols):
    """é‡‘é¡/ä»¶æ•°åˆ—ã‚’ å››æ¨äº”å…¥â†’æ•´æ•°â†’ã‚«ãƒ³ãƒæ–‡å­—åˆ— ã«å¤‰æ›ï¼ˆNAã¯ç©ºæ–‡å­—ï¼‰"""
    cols = [c for c in cols if c in df.columns]
    if not cols:
        return df
    for c in cols:
        s = pd.to_numeric(df[c], errors="coerce").round(0)
        df[c] = s.apply(lambda v: "" if pd.isna(v) else f"{int(v):,}")
    return df
def fmt_percent(df: pd.DataFrame, cols):
    """æ¯”ç‡(0.0ã€œ1.0)ã§ã‚‚ç™¾åˆ†ç‡(0ã€œ100)ã§ã‚‚å—ã‘å–ã‚Šã€xx.x% æ–‡å­—åˆ—ã«çµ±ä¸€"""
    cols = [c for c in cols if c in df.columns]
    if not cols:
        return df
    for c in cols:
        s = pd.to_numeric(df[c], errors="coerce")
        # å¤šæ•°ãŒ 0ã€œ1 ã«åã¾ã‚‹å ´åˆã¯æ¯”ç‡ã¨ã¿ãªã—ã¦ 100 å€
        with pd.option_context('mode.use_inf_as_na', True):
            non_na = s.dropna()
        if not non_na.empty and (non_na.between(0, 1).mean() >= 0.6):
            s = s * 100
        df[c] = s.round(1).apply(lambda v: "" if pd.isna(v) else f"{v:.1f}")
    return df
def sty(df: pd.DataFrame) -> "pd.io.formats.style.Styler":
    """% ä»¥å¤–ã¯å°æ•°ç‚¹ãªã—ã€å¹´ã¯ã‚«ãƒ³ãƒãªã—"""
    fmts: dict[str, str] = {}
    for c in df.columns:
        if c.endswith("%"):
            fmts[c] = "{:+.1f}"  # å¢—æ¸›ç‡ã¯ Â±1 æ¡
        elif pd.api.types.is_numeric_dtype(df[c]):
            fmts[c] = "{:,.0f}"   # æ•´æ•°(åƒåŒºåˆ‡ã‚Š) å°æ•°ç„¡ã—
        if c == "å¹´":
            fmts[c] = "{:d}"    # ã‚«ãƒ³ãƒãªã—
    return df.style.format(fmts)
def _has_cols(df: pd.DataFrame | None, cols: list[str]) -> bool:
    return isinstance(df, pd.DataFrame) and (not df.empty) and set(cols).issubset(df.columns)

# ------------------ LTV / ã‚«ãƒ«ãƒ†ï¼ˆExcelç”±æ¥ï¼‰ ------------------
def parse_ltv(file_bytes: io.BytesIO):
    try:
        file_bytes.seek(0)
        df = pd.read_excel(file_bytes, sheet_name="åº—èˆ—åˆ†æ", header=None, engine="openpyxl")
    except Exception:
        return None
    tgt_col = None
    for r in range(0, min(30, df.shape[0])):
        for c in range(df.shape[1]):
            if re.search(r"(ä»Šæœˆ|å½“æœˆ)å®Ÿç¸¾", str(df.iat[r, c])):
                tgt_col = c; break
        if tgt_col is not None: break
    row_idx = None
    for r in range(df.shape[0]):
        row_text = " ".join(str(x) for x in df.iloc[r, :5].tolist())
        if "LTV" in row_text:
            row_idx = r; break
    if row_idx is None or tgt_col is None:
        return None
    return _num(df.iat[row_idx, tgt_col])

def parse_card_count(file_bytes: io.BytesIO):
    try:
        file_bytes.seek(0)
        df = pd.read_excel(file_bytes, sheet_name="åº—èˆ—åˆ†æ", header=None, engine="openpyxl")
    except Exception:
        return None
    tgt_col = None
    for r in range(0, min(30, df.shape[0])):
        for c in range(df.shape[1]):
            if re.search(r"(ä»Šæœˆ|å½“æœˆ)å®Ÿç¸¾", str(df.iat[r, c])):
                tgt_col = c; break
        if tgt_col is not None: break
    row_idx = None
    for r in range(df.shape[0]):
        row_text = " ".join(str(x) for x in df.iloc[r, :5].tolist())
        if re.search(r"ã‚«ãƒ«ãƒ†.*æš", row_text):
            row_idx = r; break
    if row_idx is None or tgt_col is None:
        return None
    return _num(df.iat[row_idx, tgt_col])

# ------------------ å£²ä¸Šç®¡ç†è¡¨ èª­ã¿å–ã‚Š ------------------
def _detect_header_row(df_raw: pd.DataFrame) -> int:
    for i in range(min(40, len(df_raw))):
        if df_raw.iloc[i].astype(str).str.contains("æ—¥ä»˜").any():
            return i
    return 0

def read_sales_sheet(file_bytes: io.BytesIO) -> pd.DataFrame:
    file_bytes.seek(0)
    raw = pd.read_excel(file_bytes, sheet_name="å£²ä¸Šç®¡ç†", header=None, engine="openpyxl")
    header_row = _detect_header_row(raw)
    header = raw.iloc[header_row].astype(str).tolist()

    date_idx = next((j for j, v in enumerate(header) if "æ—¥ä»˜" in str(v)), 0)
    data_rows = raw.iloc[header_row+1:].copy()

    def find_right_neighbor_idx(hdr, pat):
        s = pd.Series(hdr).astype(str)
        hit = s[s.str.contains(pat, na=False)]
        if hit.empty:
            return None
        base_idx = int(hit.index[0]); neighbor = base_idx + 1
        return neighbor if neighbor < len(hdr) else None

    idx_ins = find_right_neighbor_idx(header, r"ä¿é™ºè¨ºç™‚")
    idx_sp  = find_right_neighbor_idx(header, r"è‡ªç”±è¨ºç™‚")
    if idx_ins is None: idx_ins = 4
    if idx_sp  is None: idx_sp  = 7

    valid_mask = pd.to_datetime(data_rows.iloc[:, date_idx], errors="coerce").notna()
    ins_abs = pd.to_numeric(data_rows.iloc[:, idx_ins], errors="coerce").where(valid_mask, 0).fillna(0)
    sp_abs  = pd.to_numeric(data_rows.iloc[:, idx_sp ], errors="coerce").where(valid_mask, 0).fillna(0)

    file_bytes.seek(0)
    df = pd.read_excel(file_bytes, sheet_name="å£²ä¸Šç®¡ç†", header=header_row, engine="openpyxl")
    df["æ—¥ä»˜"] = pd.to_datetime(df["æ—¥ä»˜"], errors="coerce")
    df = df.dropna(subset=["æ—¥ä»˜"]).reset_index(drop=True)

    def _find_col(patterns):
        for c in df.columns:
            for p in patterns:
                if re.search(p, str(c)):
                    return c
        return None
    if "ç·å£²ä¸Š" not in df.columns:
        alt_sales = _find_col([r"ç·å£²ä¸Š", r"å£²ä¸Šåˆè¨ˆ", r"åˆè¨ˆå£²ä¸Š", r"å£²ä¸Š\s*è¨ˆ"])
        if alt_sales is not None:
            df["ç·å£²ä¸Š"] = pd.to_numeric(df[alt_sales], errors="coerce").fillna(0)
    if "ç·æ¥é™¢æ•°" not in df.columns:
        alt_vis = _find_col([r"ç·æ¥é™¢", r"æ¥é™¢æ•°", r"æ‚£è€…æ•°"])
        if alt_vis is not None:
            df["ç·æ¥é™¢æ•°"] = pd.to_numeric(df[alt_vis], errors="coerce").fillna(0)

    for col in ("ç·å£²ä¸Š", "ç·æ¥é™¢æ•°"):
        if col in df.columns:
            df[col] = (
                df[col].astype(str).str.replace(r"[â–²â–³â–²âˆ’-]", "-", regex=True)
                                 .str.replace(r"[^0-9\.-]", "", regex=True)
                                 .replace("", "0")
            )
            df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0)

    df["ä¿é™ºæ–°æ‚£"] = ins_abs.reset_index(drop=True).iloc[:len(df)].to_numpy()
    df["è‡ªç”±æ–°æ‚£"] = sp_abs.reset_index(drop=True).iloc[:len(df)].to_numpy()

    cols = [c for c in ["æ—¥ä»˜","ç·å£²ä¸Š","ç·æ¥é™¢æ•°","ä¿é™ºæ–°æ‚£","è‡ªç”±æ–°æ‚£"] if c in df.columns]
    return df[cols]
# â”€â”€â”€â”€â”€ æ‚£è€…åˆ†æã‚·ãƒ¼ãƒˆ â”€â”€â”€â”€â”€

def parse_patient_analysis(f, add_msg):
    """æ‚£è€…åˆ†æã‚·ãƒ¼ãƒˆã‚’æŠ½å‡ºã€‚ç„¡ã„/æ¬ è½æ™‚ã¯ 0 ãƒ‡ãƒ¼ã‚¿ã§è¿”ã™"""
    # æ±ºã‚æ‰“ã¡ã‚«ãƒ†ã‚´ãƒª
    C_GENDER = ["ç”·æ€§", "å¥³æ€§"]
    C_REASON = ["ãƒãƒ©ã‚·", "ç´¹ä»‹", "çœ‹æ¿", "ãƒãƒƒãƒˆ", "ãã®ä»–"]
    C_AGE    = ["10ä»£æœªæº€", "10ä»£", "20ä»£", "30ä»£", "40ä»£", "50ä»£", "60ä»£", "70ä»£", "80ä»£", "90æ­³ä»¥ä¸Š"]

    zero = lambda cats: pd.DataFrame({"ã‚«ãƒ†ã‚´ãƒª": cats, "ä»¶æ•°": [0]*len(cats)})

    try:
        xls = pd.ExcelFile(f, engine="openpyxl")
        if "æ‚£è€…åˆ†æ" not in xls.sheet_names:
            raise ValueError("ã‚·ãƒ¼ãƒˆãªã—")
        sheet = xls.parse("æ‚£è€…åˆ†æ", header=None)
    except Exception:
        add_msg(f"{f.name}: æ‚£è€…åˆ†æã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ - 0 ä»¶ã¨ã—ã¦å‡¦ç†ã—ã¾ã™")
        return zero(C_GENDER), zero(C_REASON), zero(C_AGE)

    def grab(keyword: str, rng: slice | None, cats: list[str]):
        mask = sheet.apply(lambda r: r.astype(str).str.contains(keyword).any(), axis=1)
        if not mask.any():
            return zero(cats)
        r = mask.idxmax()
        # ãƒ‡ãƒ¼ã‚¿è¡ŒãŒè¶³ã‚Šãªã„å ´åˆã¯ 0
        if r + 2 >= len(sheet):
            add_msg(f"{f.name}: æ‚£è€…åˆ†æã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ - 0 ä»¶ã¨ã—ã¦å‡¦ç†ã—ã¾ã™")
            return zero(cats)
        header = sheet.iloc[r + 1]
        vals   = sheet.iloc[r + 2]
        if rng is not None:
            header = header.iloc[rng]
            vals   = vals.iloc[rng]
        header = header.dropna()
        if header.empty:
            return zero(cats)
        data = pd.to_numeric(vals[header.index], errors="coerce").fillna(0)
        return pd.DataFrame({"ã‚«ãƒ†ã‚´ãƒª": header.values, "ä»¶æ•°": data.values})

    gender = grab("ç”·å¥³æ¯”ç‡",  slice(0, 2),  C_GENDER)  # A:B
    reason = grab("æ¥é™¢å‹•æ©Ÿ", slice(5, 10), C_REASON)  # F:J
    age    = grab("å¹´é½¢æ¯”ç‡", None,        C_AGE)
    return gender, reason, age
# æ‚£è€…åˆ†æãƒ—ãƒ­ãƒƒãƒˆ
def plot_pivot(df_src, store, latest, title):
    # â˜…åˆ—ãŒç„¡ã„/ç©ºãªã‚‰ä½•ã‚‚æã‹ãšè¿”ã™ï¼ˆæœªèª­è¾¼æ™‚ã®é˜²å¼¾ï¼‰
    if not _has_cols(df_src, ["åº—èˆ—å", "å¹´", "ã‚«ãƒ†ã‚´ãƒª", "ä»¶æ•°"]):
        st.info(f"{title}ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # ãƒ–ãƒ¼ãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§æŠ½å‡ºï¼ˆqueryã¯ä½¿ã‚ãªã„ï¼‰
    mask = (
        (df_src["åº—èˆ—å"].astype(str) == str(store)) &
        (pd.to_numeric(df_src["å¹´"], errors="coerce") == int(latest))
    )
    df = (df_src.loc[mask, ["ã‚«ãƒ†ã‚´ãƒª", "ä»¶æ•°"]]
                 .groupby("ã‚«ãƒ†ã‚´ãƒª", as_index=False)["ä»¶æ•°"].sum())

    if df.empty:
        st.info(f"{store}ï¼ˆ{latest}å¹´ï¼‰ã®{title}ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    df["å‰²åˆ%"] = (df["ä»¶æ•°"] / df["ä»¶æ•°"].sum() * 100).round(1)
    st.altair_chart(
        alt.Chart(df).mark_bar().encode(
            y=alt.Y("ã‚«ãƒ†ã‚´ãƒª:N", sort="-x"),
            x="ä»¶æ•°:Q",
            tooltip=["ã‚«ãƒ†ã‚´ãƒª", "ä»¶æ•°", "å‰²åˆ%"],
        ).properties(width=350, height=250, title=title),
        use_container_width=True,
    )
    with st.expander(f"ğŸ“„ {title} æ˜ç´°"):
        st.dataframe(df, use_container_width=True)

# â”€â”€â”€â”€â”€ ä»»æ„ã‚«ãƒ†ã‚´ãƒªï¼šå‰å¹´æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆ â”€â”€â”€â”€â”€
# â”€â”€â”€â”€â”€ ä»»æ„ã‚«ãƒ†ã‚´ãƒªï¼šå‰å¹´æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆ â”€â”€â”€â”€â”€
def plot_cat_yoy(df_src, store, latest, prev, title):
    # â˜…åˆ—ãŒç„¡ã„/ç©ºãªã‚‰ä½•ã‚‚æã‹ãšè¿”ã™
    if not _has_cols(df_src, ["åº—èˆ—å", "å¹´", "ã‚«ãƒ†ã‚´ãƒª", "ä»¶æ•°"]):
        st.info(f"{title}ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # ä»Šå¹´/å‰å¹´ã‚’ãƒ–ãƒ¼ãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§æŠ½å‡º
    cur_mask = ((df_src["åº—èˆ—å"].astype(str) == str(store)) &
                (pd.to_numeric(df_src["å¹´"], errors="coerce") == int(latest)))
    prv_mask = ((df_src["åº—èˆ—å"].astype(str) == str(store)) &
                (pd.to_numeric(df_src["å¹´"], errors="coerce") == int(prev)))

    cur = (df_src.loc[cur_mask, ["ã‚«ãƒ†ã‚´ãƒª", "ä»¶æ•°"]]
                 .groupby("ã‚«ãƒ†ã‚´ãƒª", as_index=False)["ä»¶æ•°"].sum()
                 .rename(columns={"ä»¶æ•°": "ä»Šå¹´"}))
    old = (df_src.loc[prv_mask, ["ã‚«ãƒ†ã‚´ãƒª", "ä»¶æ•°"]]
                 .groupby("ã‚«ãƒ†ã‚´ãƒª", as_index=False)["ä»¶æ•°"].sum()
                 .rename(columns={"ä»¶æ•°": "å‰å¹´"}))

    comp = pd.merge(cur, old, on="ã‚«ãƒ†ã‚´ãƒª", how="outer").fillna(0)

    # ---------- ã‚°ãƒ©ãƒ• ----------
    comp_melt = (comp.rename(columns={"å‰å¹´": str(prev), "ä»Šå¹´": str(latest)})
                       .melt(id_vars="ã‚«ãƒ†ã‚´ãƒª",
                             value_vars=[str(prev), str(latest)],
                             var_name="å¹´åº¦", value_name="ä»¶æ•°"))

    chart = (
        alt.Chart(comp_melt)
           .mark_bar()
           .encode(
               x=alt.X("ã‚«ãƒ†ã‚´ãƒª:N", sort="-y", title=title),
               y="ä»¶æ•°:Q",
               xOffset=alt.XOffset("å¹´åº¦:N",
                                   scale=alt.Scale(domain=[str(prev), str(latest)])),
               color=alt.Color("å¹´åº¦:N",
                               scale=alt.Scale(domain=[str(prev), str(latest)],
                                               range=["#4e79a7", "#a0cbe8"])),
               tooltip=["å¹´åº¦", "ã‚«ãƒ†ã‚´ãƒª", "ä»¶æ•°"],
           )
           .properties(width=400, height=300,
                       title=f"{store} {title} ({prev} vs {latest})")
    )
    st.altair_chart(chart, use_container_width=True)

    # ---------- å¢—æ¸›ãƒ†ãƒ¼ãƒ–ãƒ« ----------
    diff_tbl = (comp.set_index("ã‚«ãƒ†ã‚´ãƒª")
                     .apply(pd.to_numeric, errors="coerce")
                     .fillna(0))
    diff_tbl["å¢—æ¸›å·®"]  = diff_tbl["ä»Šå¹´"] - diff_tbl["å‰å¹´"]
    diff_tbl["å¢—æ¸›ç‡%"] = np.where(
        diff_tbl["å‰å¹´"] == 0, np.nan,
        (diff_tbl["å¢—æ¸›å·®"] / diff_tbl["å‰å¹´"] * 100).round(1)
    )
    with st.expander(f"ğŸ“„ {title} å¢—æ¸›æ˜ç´°"):
        st.dataframe(sty(diff_tbl.reset_index()), use_container_width=True)


def infer_year_month(df: pd.DataFrame) -> Tuple[int, int]:
    day = pd.to_datetime(df["æ—¥ä»˜"], errors="coerce").dropna()
    if day.empty:
        now = pd.Timestamp.today()
        return int(now.year), int(now.month)
    return int(day.dt.year.mode()[0]), int(day.dt.month.mode()[0])

def _store_from_filename(name: str) -> str:
    base = re.sub(r"\.xlsx$", "", name)
    base = re.sub(r"^\d+[\.\sï¼¿-]*", "", base)
    base = re.sub(r"\s*\d{1,2}æœˆ.*$", "", base)
    return canonical_store_name(base)   # â† ã“ã“ã‚’è¿½åŠ 

# ç½®ãæ›ãˆï¼š@st.cache_data ã‚’ä»˜ã‘ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 
@st.cache_data(show_spinner=False)
def load(files, *, read_ltv=True, read_card=True, read_patient=True):
    total = len(files) if files else 0
    bar = st.progress(0, text="ğŸ“¥ å£²ä¸Šç®¡ç†è¡¨ã‚’èª­ã¿å–ã‚Šæº–å‚™â€¦") if total else None

    sales, reasons, genders, ages, ltvs, cards = [], [], [], [], [], []
    msgs = []
    for i, up in enumerate(files, start=1):
        if bar:
            bar.progress(int(i*100/total), text=f"ğŸ“– {getattr(up,'name','ãƒ•ã‚¡ã‚¤ãƒ«')} ã‚’èª­ã¿å–ã‚Šä¸­â€¦ï¼ˆ{i}/{total}ï¼‰")
        name = getattr(up, "name", "å£²ä¸Šç®¡ç†è¡¨.xlsx")
        try:
            data = up.getvalue() if hasattr(up, "getvalue") else (up.seek(0) or up.read())
            file_bytes = BytesIO(data) if isinstance(data, (bytes, bytearray)) else up
            setattr(file_bytes, "name", name)

            # å£²ä¸Šãƒ»æ¥é™¢ãƒ»æ–°æ‚£ï¼ˆå¿…é ˆï¼‰
            df = read_sales_sheet(file_bytes)
            y, m = infer_year_month(df)
            store = _store_from_filename(name)
            agg = {
                "ç·å£²ä¸Š":   pd.to_numeric(df["ç·å£²ä¸Š"], errors="coerce").sum(),
                "ç·æ¥é™¢æ•°": pd.to_numeric(df["ç·æ¥é™¢æ•°"], errors="coerce").sum(),
                "ä¿é™ºæ–°æ‚£": pd.to_numeric(df["ä¿é™ºæ–°æ‚£"], errors="coerce").sum(),
                "è‡ªç”±æ–°æ‚£": pd.to_numeric(df["è‡ªç”±æ–°æ‚£"], errors="coerce").sum(),
            }
            sales.append({"åº—èˆ—å": store, "å¹´": y, "æœˆ": m, **agg})

            # LTV / ã‚«ãƒ«ãƒ†ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            if read_ltv:
                ltv = parse_ltv(file_bytes)
                if ltv is not None:
                    ltvs.append({"åº—èˆ—å": store, "å¹´": y, "æœˆ": m, "LTV": ltv})
            if read_card:
                card = parse_card_count(file_bytes)
                if card is not None:
                    cards.append({"åº—èˆ—å": store, "å¹´": y, "æœˆ": m, "ã‚«ãƒ«ãƒ†æšæ•°": card})

        except Exception as e:
            msgs.append(f"{name}: èª­ã¿å–ã‚Šå¤±æ•—ï¼ˆ{e}ï¼‰")

        # æ‚£è€…åˆ†æï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if read_patient:
            def _add_msg(msg): msgs.append(str(msg))
            try:
                file_bytes.seek(0)
                gdf, rdf, adf = parse_patient_analysis(file_bytes, _add_msg)
                for _df, bucket in [(rdf, reasons), (gdf, genders), (adf, ages)]:
                    if _df is not None and not _df.empty:
                        d = _df.copy()
                        d["åº—èˆ—å"] = store; d["å¹´"] = y; d["æœˆ"] = m
                        bucket.append(d)
            except Exception as e:
                msgs.append(f"{name}: æ‚£è€…åˆ†æ èª­ã¿å–ã‚Šå¤±æ•—ï¼ˆ{e}ï¼‰")

    if bar:
        bar.progress(100, text=f"âœ… å£²ä¸Šç®¡ç†è¡¨ {total} ä»¶ å–ã‚Šè¾¼ã¿å®Œäº†")
        time.sleep(0.2); bar.empty()

    def _to_df(lst):
        if not lst: return pd.DataFrame()
        first = lst[0]
        if isinstance(first, (pd.DataFrame, pd.Series)):
            return pd.concat(lst, ignore_index=True)
        return pd.DataFrame(lst)

    return _to_df(sales), _to_df(reasons), _to_df(genders), _to_df(ages), pd.DataFrame(ltvs), pd.DataFrame(cards), msgs


# ------------------ äºˆå®Ÿç®¡ç†ï¼ˆã‚·ãƒ¼ãƒˆé€²æ—ã¤ãï¼‰ ------------------
def _yj_parse_with_sheet_progress(file_like):
    import numpy as np, re, pandas as pd
    from openpyxl import load_workbook
    from contextlib import suppress

    def to_num(x):
        if x is None:
            return float("nan")
        if isinstance(x, (int, float)):
            return float(x)
        s = str(x)
        s = re.sub(r"[â–²â–³âˆ’\-]", "-", s)
        s = re.sub(r"[^0-9\.\-]", "", s)
        try:
            return float(s) if s != "" else float("nan")
        except Exception:
            return float("nan")

    exp_keys = [
        "åºƒå‘Šå®£ä¼è²»","è·é€ é‹è³ƒ","çµ¦æ–™æ‰‹å½“","æ³•å®šç¦åˆ©è²»","åšç”Ÿè²»","æ¸›ä¾¡å„Ÿå´è²»","è² å‚µæ–™","ä¿®ç¹•è²»","ä¿é™ºæ–™","è³ƒå€Ÿæ–™",
        "äº‹å‹™ç”¨å“è²»","æ¶ˆè€—å“è²»","æ°´é“å…‰ç†±è²»","æ—…è²»äº¤é€šè²»","æ‰‹æ•°æ–™","ç§Ÿç¨å…¬èª²","é€šä¿¡è²»","è«¸ä¼šè²»",
        "æ–°èå›³æ›¸è²»","åœ°ä»£å®¶è³ƒ","ç‡ƒæ–™è²»","ãƒªãƒ¼ã‚¹æ–™","é›‘è²»","é§è»Šå ´è² æ‹…é‡‘","é§è»Šå ´è² æ‹…é‡‘ï¼ˆæ‚£è€…ï¼‰","æŸ”é“æ•´ä¼šè² æ‹…é‡‘","ç ”ä¿®è²»"
    ]
    sale_keys = ["ç´”å£²ä¸Š", "ç´”å£²ä¸Šé«˜", "å£²ä¸Šåˆè¨ˆ", "ç·å£²ä¸Š", "å£²ä¸Šé«˜"]

    wb = load_workbook(file_like, read_only=True, data_only=True)
    sheet_names = [s for s in wb.sheetnames if all(x not in s for x in ["ä¸€è¦§","åˆè¨ˆ"])]

    rows = []
    try:
        st_status = st.status("ğŸ“˜ äºˆå®Ÿãƒ–ãƒƒã‚¯ã‚’è§£æä¸­â€¦", expanded=False)
    except Exception:
        st_status = None

    for i, sheet in enumerate(sheet_names, start=1):
        if st_status:
            with suppress(Exception):
                st_status.update(label=f"[{i}/{len(sheet_names)}] ã€{sheet}ã€ã‚’èª­ã¿å–ã‚Šä¸­â€¦")

        ws = wb[sheet]
        MAX_R, MAX_C = 180, 200

        header_row = item_col = year = None
        for r in range(1, min(MAX_R, ws.max_row)+1):
            for c in range(1, min(MAX_C, ws.max_column)+1):
                if ws.cell(r, c).value == "ç§‘ç›®":
                    header_row, item_col = r, c
                    for c2 in range(c+1, min(c+60, ws.max_column)+1):
                        hv = str(ws.cell(r, c2).value or "")
                        m = re.search(r"(\d{4})ç›®æ¨™", hv)
                        if m:
                            year = int(m.group(1)); break
                    break
            if header_row is not None: break
        if header_row is None or item_col is None:
            continue

        def _left_group_label(col):
            for cc in range(col, max(item_col, col-10), -1):
                s = ws.cell(header_row, cc).value
                if s is not None and str(s).strip() != "":
                    return str(s)
            return ""

        tgt_cols, act_cols = {}, {}
        for c in range(item_col+1, min(item_col+80, ws.max_column)+1):
            sub = str(ws.cell(header_row+1, c).value or "")
            m = re.fullmatch(r"(\d{1,2})æœˆ", sub)
            if not m:
                continue
            top_label = _left_group_label(c)
            if "å®Ÿç¸¾" in top_label:
                mth = int(m.group(1))
                act_cols[mth] = c
                tgt_cols[mth] = c - 2

        if not act_cols:
            continue

        sale_row = None
        exp_rows = []
        for r in range(header_row+1, min(header_row+100, ws.max_row)+1):
            label = str(ws.cell(r, item_col).value or "")
            if any(k in label for k in sale_keys): sale_row = r
            if any(k in label for k in exp_keys): exp_rows.append(r)

        store = re.sub(r"^\d+\s*", "", sheet).strip()
        months = sorted(act_cols.keys())
        max_act = months[-1] if months else None

        top_goal = None
        for r in range(1, 40):
            for c in range(1, 80):
                v = ws.cell(r, c).value
                if isinstance(v, str) and "å£²ä¸Šç›®æ¨™" in v:
                    n = to_num(ws.cell(r, c+1).value)
                    if n == n: top_goal = n; break
            if top_goal is not None: break

        for mth in months:
            rec = {"åº—èˆ—å": store, "å¹´": year, "æœˆ": mth}
            if sale_row is not None:
                if mth in tgt_cols: rec["å£²ä¸Šç›®æ¨™"] = to_num(ws.cell(sale_row, tgt_cols[mth]).value)
                if mth in act_cols: rec["å£²ä¸Šå®Ÿç¸¾"] = to_num(ws.cell(sale_row, act_cols[mth]).value)
            def _nansum_cells(ws, rows, col):
                vals = [to_num(ws.cell(r, col).value) for r in rows]
                return float(np.nansum(vals))  # NaN ã‚’ 0 ã¨ã—ã¦åˆè¨ˆ

            if exp_rows:
                if mth in tgt_cols: rec["çµŒè²»ç›®æ¨™"] = _nansum_cells(ws, exp_rows, tgt_cols[mth])
                if mth in act_cols: rec["çµŒè²»å®Ÿç¸¾"] = _nansum_cells(ws, exp_rows, act_cols[mth])
            
            rows.append(rec)

        if rows and top_goal is not None and max_act is not None:
            for rec in reversed(rows):
                if rec.get("åº—èˆ—å")==store and rec.get("å¹´")==year and rec.get("æœˆ")==max_act:
                    rec["å£²ä¸Šç›®æ¨™"] = top_goal
                    break

    out = pd.DataFrame(rows)
    if st_status:
        with suppress(Exception):
            st_status.update(label="âœ… äºˆå®Ÿãƒ–ãƒƒã‚¯è§£æ å®Œäº†", state="complete")

    if not out.empty:
        import numpy as np
        out["ç²—åˆ©ç›®æ¨™"] = out.get("å£²ä¸Šç›®æ¨™", np.nan) - out.get("çµŒè²»ç›®æ¨™", np.nan)
        out["ç²—åˆ©å®Ÿç¸¾"] = out.get("å£²ä¸Šå®Ÿç¸¾", np.nan) - out.get("çµŒè²»å®Ÿç¸¾", np.nan)
        out["ç²—åˆ©ç‡ç›®æ¨™"] = np.where(out.get("å£²ä¸Šç›®æ¨™", np.nan).fillna(0)==0, np.nan, out["ç²—åˆ©ç›®æ¨™"]/out["å£²ä¸Šç›®æ¨™"]*100)
        out["ç²—åˆ©ç‡å®Ÿç¸¾"] = np.where(out.get("å£²ä¸Šå®Ÿç¸¾", np.nan).fillna(0)==0, np.nan, out["ç²—åˆ©å®Ÿç¸¾"]/out["å£²ä¸Šå®Ÿç¸¾"]*100)
    return out

def parse_yj_workbook(file_like):
    return _yj_parse_with_sheet_progress(file_like)

@st.cache_data(show_spinner=False)
def load_yj(files):
    if not files:
        return pd.DataFrame()
    dfs = []
    total = len(files)
    bar = st.progress(0, text="ğŸ“¥ äºˆå®Ÿç®¡ç†ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿å–ã‚Šæº–å‚™â€¦")
    for i, up in enumerate(files, start=1):
        name = getattr(up, "name", "äºˆå®Ÿãƒ–ãƒƒã‚¯.xlsx")
        bar.progress(int(i*100/total), text=f"ğŸ“– {name} ã‚’èª­ã¿å–ã‚Šä¸­â€¦ï¼ˆ{i}/{total}ï¼‰")
        try:
            data = up.getvalue() if hasattr(up, "getvalue") else (up.seek(0) or up.read())
            buf = BytesIO(data) if isinstance(data, (bytes, bytearray)) else up
            df = _yj_parse_with_sheet_progress(buf)
            if df is not None and not df.empty:
                df = df.copy(); df["å…ƒãƒ•ã‚¡ã‚¤ãƒ«"] = name
                dfs.append(df)
        except Exception as e:
            st.warning(f"äºˆå®Ÿãƒ•ã‚¡ã‚¤ãƒ«ã®èª­è¾¼ã«å¤±æ•—: {name} â€¦ {e}")
    if not dfs:
        bar.empty(); return pd.DataFrame()
    bar.progress(100, text=f"âœ… äºˆå®Ÿç®¡ç†ãƒ•ã‚¡ã‚¤ãƒ« {total} ä»¶ å–ã‚Šè¾¼ã¿å®Œäº†")
    time.sleep(0.2); bar.empty()
    yj = pd.concat(dfs, ignore_index=True)
    yj = yj.sort_values(["åº—èˆ—å","å¹´","æœˆ"]).drop_duplicates(subset=["åº—èˆ—å","å¹´","æœˆ"], keep="last")
    return yj

# ------------------ å€‹äººç”Ÿç”£æ€§ï¼ˆæ–°å®Ÿè£…ï¼‰ ------------------
def _guess_year_month_from_sheet(df: pd.DataFrame, sheet_name: str, file_name: str):
    """
    å¹´æœˆã®æ¨å®šã‚’å¼·åŒ–ï¼š
      - ã¾ãšã‚¿ãƒ–å 'YYMM' ã‚’ 20YY/MM ã¨è§£é‡ˆï¼ˆä¾‹: 2506â†’2025/6ï¼‰
      - æ¬¡ã« '20YY' + åŒºåˆ‡ã‚Š + 'MM'ï¼ˆä¾‹: 2025-06, 2025_6, 202506ï¼‰
      - ã‚·ãƒ¼ãƒˆä¸Šéƒ¨ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ã€Œå¹´ã€ã€Œæœˆã€ã®æ–‡è„ˆãŒã‚ã‚‹çµ„åˆã›ã®ã¿æ¡ç”¨
      - ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ã®ä¿é™ºï¼ˆ202506 / 2025-06 / YYMMï¼‰ã«ã‚‚å¯¾å¿œ
    """
    sname = str(sheet_name).strip()
    fname = str(file_name).strip()

    # 1) ã‚¿ãƒ–åãŒ YYMMï¼ˆ4æ¡ã®ã¿ï¼‰ãªã‚‰ 2000+YY / MM
    m = re.fullmatch(r"(\d{2})([01]\d)", sname)
    if m:
        yy, mm = int(m.group(1)), int(m.group(2))
        if 1 <= mm <= 12:
            return 2000 + yy, mm

    # 2) ã‚¿ãƒ–å: 20YY + åŒºåˆ‡ã‚Š? + MM
    m = re.search(r"(20\d{2})\D{0,3}([01]?\d)\b", sname)
    if m:
        y, mth = int(m.group(1)), int(m.group(2))
        if 1 <= mth <= 12:
            return y, mth

    # 3) ã‚·ãƒ¼ãƒˆä¸Šéƒ¨ï¼ˆA1ï½ã®æ•°è¡ŒÃ—æ•°åˆ—ï¼‰ã‹ã‚‰ã€å¹´ãƒ»æœˆã®â€œçµ„åˆã›â€ã§æ‹¾ã†
    def _top_blob(df):
        top = df.iloc[:8, :10].astype(str).fillna("")
        return " ".join(top.values.ravel())

    blob = _top_blob(df)

    # 2025å¹´6æœˆ / 6æœˆ 2025å¹´ ãªã©
    m = re.search(r"(20\d{2})\s*å¹´\D{0,3}([01]?\d)\s*æœˆ", blob)
    if m:
        y, mth = int(m.group(1)), int(m.group(2))
        if 1 <= mth <= 12:
            return y, mth

    m = re.search(r"([01]?\d)\s*æœˆ\D{0,5}(20\d{2})", blob)
    if m:
        mth, y = int(m.group(1)), int(m.group(2))
        if 1 <= mth <= 12:
            return y, mth

    # æœˆã ã‘è¦‹ã¤ã‹ã£ãŸã‚‰ã€å¹´ã¯ãƒ•ã‚¡ã‚¤ãƒ«å/ã‚¿ãƒ–åã® 20YY ã‚’æ¡ç”¨
    m = re.search(r"([01]?\d)\s*æœˆ", blob)
    if m:
        mth = int(m.group(1))
        y = None
        m_y = re.search(r"(20\d{2})", sname) or re.search(r"(20\d{2})", fname)
        if m_y:
            y = int(m_y.group(1))
        if y and 1 <= mth <= 12:
            return y, mth

    # 4) ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ã®ä¿é™º: 202506 / 2025-06 / YYMM
    m = re.search(r"(20\d{2})\D{0,3}([01]?\d)\b", fname)
    if m:
        y, mth = int(m.group(1)), int(m.group(2))
        if 1 <= mth <= 12:
            return y, mth
    m = re.search(r"(?<!\d)(\d{2})([01]\d)(?!\d)", fname)
    if m:
        yy, mm = int(m.group(1)), int(m.group(2))
        if 1 <= mm <= 12:
            return 2000 + yy, mm

    return None, None

    """ã‚·ãƒ¼ãƒˆä¸Šéƒ¨ãƒ»ã‚·ãƒ¼ãƒˆåãƒ»ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ å¹´ãƒ»æœˆ ã‚’æ¨å®š"""
    year = None; month = None
    # 1) ã‚·ãƒ¼ãƒˆä¸Šéƒ¨
    top = df.iloc[:6, :8].astype(str).fillna("")
    blob = " ".join(top.values.ravel())
    m = re.search(r"(\d{1,2})\s*æœˆ", blob)
    if m: month = int(m.group(1))
    y = re.search(r"(20\d{2})", blob)
    if y: year = int(y.group(1))
    # 2) ã‚·ãƒ¼ãƒˆå
    if month is None:
        m2 = re.search(r"(\d{1,2})\s*æœˆ", sheet_name)
        if m2: month = int(m2.group(1))
    if year is None:
        y2 = re.search(r"(20\d{2})", sheet_name)
        if y2: year = int(y2.group(1))
    # 3) ãƒ•ã‚¡ã‚¤ãƒ«å
    if year is None:
        y3 = re.search(r"(20\d{2})", file_name)
        if y3: year = int(y3.group(1))
    return year, month

def parse_person_book(file_like, filename: str):
    """å„æœˆã‚·ãƒ¼ãƒˆã‹ã‚‰ é™¢/æ‹…å½“è€… ã®ã€ç¨¼åƒæ•°ãƒ»ç›®æ¨™å€¤/æ—¥ãƒ»ç›®æ¨™å€¤/æœˆãƒ»é€²æ—ãƒ»é”æˆç‡ã€ã‚’æŠ½å‡º"""
    logs = []
    xls = pd.ExcelFile(file_like, engine="openpyxl")
    store = _store_from_filename(filename)
    recs = []

    for sh in xls.sheet_names:
        df = xls.parse(sh, header=None)
        if df.empty:
            logs.append(f"{filename}:{sh} â€¦ ç©ºã‚·ãƒ¼ãƒˆ")
            continue

        y, m = _guess_year_month_from_sheet(df, sh, filename)
        if not (y and m and 2000 <= int(y) <= 2100 and 1 <= int(m) <= 12):
            logs.append(f"{filename}:{sh} â€¦ å¹´æœˆãŒåˆ¤å®šã§ããš")
            continue

        firstcol = df.iloc[:, 0].astype(str)
        idx_kado = firstcol[firstcol.str.contains("ç¨¼åƒæ•°", na=False)].index
        if len(idx_kado) == 0:
            logs.append(f"{filename}:{sh} â€¦ ã€ç¨¼åƒæ•°ã€è¡ŒãŒè¦‹ã¤ã‹ã‚‰ãªã„")
            continue
        header_row = int(idx_kado[0] - 1)

        # --- æ‹…å½“ï¼ˆBåˆ—ä»¥é™ï¼‰ã€‚'0' / 'ï¼' / '0.0' ãŒæ¥ãŸã‚‰ä»¥é™ã‚’ç„¡è¦– ---
        raw_cells = df.iloc[header_row, 1:].tolist()
        staff = []
        for cell in raw_cells:
            s = "" if cell is None else str(cell).strip()
            # '0', 'ï¼', '0.0', '0.', '0,0' ãªã©ã‚’ 0 ã¨ã¿ãªã™
            s_norm = s.replace("ï¼", "0").replace(",", "")
            if s_norm == "" or re.fullmatch(r"0(?:\.0+)?", s_norm):
                break
            if s.lower() == "nan":
                break
            staff.append(s)
        if not staff:
            logs.append(f"{filename}:{sh} â€¦ æ‹…å½“è€…è¦‹å‡ºã—ï¼ˆBåˆ—ä»¥é™ï¼‰ãŒç©º")
            continue
        staff_len = len(staff)

        def find_row(pat):
            hit = firstcol[firstcol.str.contains(pat, na=False)]
            return int(hit.index[0]) if len(hit) else None

        rows = {
            "ç¨¼åƒæ•°": find_row(r"ç¨¼åƒæ•°"),
            "ç›®æ¨™å€¤_æ—¥": find_row(r"ç›®æ¨™å€¤\s*[\/ï¼]?\s*æ—¥"),
            "ç›®æ¨™å€¤_æœˆ": find_row(r"ç›®æ¨™å€¤\s*[\/ï¼]?\s*æœˆ"),
            "é€²æ—":   find_row(r"é€²æ—"),
            "é”æˆç‡": find_row(r"é”æˆç‡"),
        }
        if any(v is None for v in rows.values()):
            logs.append(f"{filename}:{sh} â€¦ å¿…é ˆè¡Œï¼ˆç¨¼åƒæ•°/ç›®æ¨™å€¤/æ—¥/ç›®æ¨™å€¤/æœˆ/é€²æ—/é”æˆç‡ï¼‰ã®ã©ã‚Œã‹ãŒä¸è¶³")
            continue

        # å„è¡Œã‚‚ 'staff_len' åˆ—ã¶ã‚“ã ã‘å–å¾—ï¼ˆ0 ä»¥é™ã¯åˆ‡ã‚Šæ¨ã¦ï¼‰
        def row_vals(ridx):
            vals = df.iloc[ridx, 1:1+staff_len].tolist()
            return [_num(v) for v in vals]

        vals = {k: row_vals(v) for k, v in rows.items()}

        for j, name in enumerate(staff):
            recs.append({
                "åº—èˆ—å": store,
                "å¹´": int(y), "æœˆ": int(m),
                "æ‹…å½“": name,                 # ã€Œé™¢ã€ã‚‚å«ã‚€
                "ç¨¼åƒæ•°": vals["ç¨¼åƒæ•°"][j] if j < len(vals["ç¨¼åƒæ•°"]) else None,
                "ç›®æ¨™å€¤_æ—¥": vals["ç›®æ¨™å€¤_æ—¥"][j] if j < len(vals["ç›®æ¨™å€¤_æ—¥"]) else None,
                "ç›®æ¨™å€¤_æœˆ": vals["ç›®æ¨™å€¤_æœˆ"][j] if j < len(vals["ç›®æ¨™å€¤_æœˆ"]) else None,
                "é€²æ—": vals["é€²æ—"][j] if j < len(vals["é€²æ—"]) else None,
                "é”æˆç‡": vals["é”æˆç‡"][j] if j < len(vals["é”æˆç‡"]) else None,
            })
        logs.append(f"{filename}:{sh} â€¦ {staff_len}å èª­ã¿å–ã‚Šï¼ˆ{y}/{m}ï¼‰")

    return pd.DataFrame(recs), logs

  

@st.cache_data(show_spinner=False)
def load_person_productivity(files):
    """å€‹äººç”Ÿç”£æ€§ãƒ•ã‚¡ã‚¤ãƒ«ç¾¤ã‚’çµ±åˆ"""
    if not files:
        return pd.DataFrame(), []
    dfs, logs = [], []
    total = len(files)
    bar = st.progress(0, text="ğŸ“¥ å€‹äººç”Ÿç”£æ€§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿å–ã‚Šæº–å‚™â€¦")
    for i, up in enumerate(files, start=1):
        name = getattr(up, "name", "person.xlsx")
        bar.progress(int(i*100/total), text=f"ğŸ“– {name} ã‚’è§£æä¸­â€¦ï¼ˆ{i}/{total}ï¼‰")
        try:
            data = up.getvalue() if hasattr(up, "getvalue") else (up.seek(0) or up.read())
            buf = BytesIO(data) if isinstance(data, (bytes, bytearray)) else up
            df_one, lg = parse_person_book(buf, name)
            logs.extend(lg)
            if not df_one.empty:
                dfs.append(df_one)
        except Exception as e:
            logs.append(f"{name}: èª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼ â€¦ {e}")
    bar.progress(100, text="âœ… å€‹äººç”Ÿç”£æ€§ å–ã‚Šè¾¼ã¿å®Œäº†")
    time.sleep(0.2); bar.empty()
    return (pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()), logs


# ------------------ UI ------------------
st.title("ğŸ“Š å£²ä¸Šãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

# 1) å£²ä¸Šç®¡ç†ãƒ•ã‚¡ã‚¤ãƒ«
st.header("ğŸ“‚ å£²ä¸Šç®¡ç†ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆåº—èˆ—ã”ã¨ãƒ»è¤‡æ•°å¯ï¼‰")
files_sales = st.file_uploader("ğŸ“‚ å£²ä¸Šç®¡ç†è¡¨ï¼ˆä¾‹: 01.åº—èˆ—å 1æœˆ å£²ä¸Šç®¡ç†è¡¨.xlsxï¼‰", type=["xlsx"], accept_multiple_files=True, key="sales_files")
# è¿½åŠ ï¼šèª­ã¿å–ã‚Šã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆé€Ÿåº¦å„ªå…ˆï¼‰
with st.expander("âš™ï¸ èª­ã¿å–ã‚Šã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆé€Ÿåº¦å„ªå…ˆï¼‰", expanded=False):
    c1, c2, c3 = st.columns(3)
    with c1:
        opt_ltv = st.checkbox("LTV ã‚’èª­ã‚€", value=True)
    with c2:
        opt_card = st.checkbox("ã‚«ãƒ«ãƒ†æšæ•°ã‚’èª­ã‚€", value=True)
    with c3:
        opt_patient = st.checkbox("æ‚£è€…åˆ†æã‚’èª­ã‚€", value=True)

sales_df = reason_df = gender_df = age_df = pd.DataFrame()
ltv_df = card_df = pd.DataFrame()
msgs = []
if files_sales:
    sales_df, reason_df, gender_df, age_df, ltv_df, card_df, msgs = load(
        files_sales,
        read_ltv=opt_ltv, read_card=opt_card, read_patient=opt_patient
    )
    # â‘¢ åº—åçµ±ä¸€ï¼ˆå£²ä¸Šç®¡ç†ï¼‰
    if not sales_df.empty:
        sales_df = unify_store_names(sales_df)
    if not ltv_df.empty:
        ltv_df = unify_store_names(ltv_df)
    if not card_df.empty:
        card_df = unify_store_names(card_df)
    if not reason_df.empty:
        reason_df = unify_store_names(reason_df)
    if not gender_df.empty:
        gender_df = unify_store_names(gender_df)
    if not age_df.empty:
        age_df = unify_store_names(age_df)
    if msgs:
        with st.expander("âš ï¸ èª­ã¿å–ã‚Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"):
            for m in msgs:
                st.write(m)

# 2) ğŸ“Š å…¨åº—èˆ—ã‚µãƒãƒªãƒ¼ï¼ˆæœ€æ–°å¹´åº¦ vs å‰å¹´ï¼‰
st.subheader("ğŸ“Š å…¨åº—èˆ—ã‚µãƒãƒªãƒ¼ï¼ˆæœ€æ–°å¹´åº¦ vs å‰å¹´ï¼‰")
if not sales_df.empty:
    monthly = (
        sales_df.groupby(["åº—èˆ—å", "å¹´", "æœˆ"], as_index=False)[
            ["ç·å£²ä¸Š", "ç·æ¥é™¢æ•°", "ä¿é™ºæ–°æ‚£", "è‡ªç”±æ–°æ‚£"]
        ].sum()
    )
    latest = int(monthly["å¹´"].max()); prev = latest - 1
    cur = monthly[monthly["å¹´"] == latest]
    old = monthly[monthly["å¹´"] == prev]
    comp = pd.merge(cur, old, on=["åº—èˆ—å","æœˆ"], how="left", suffixes=("_ä»Šå¹´","_å‰å¹´"))

    # LTV
    if not ltv_df.empty:
        ltv_cur = ltv_df[ltv_df["å¹´"] == latest].rename(columns={"LTV":"LTV_ä»Šå¹´"})
        ltv_old = ltv_df[ltv_df["å¹´"] == prev].rename(columns={"LTV":"LTV_å‰å¹´"})
        ltv_c = pd.merge(ltv_cur, ltv_old, on=["åº—èˆ—å","æœˆ"], how="left")[["åº—èˆ—å","æœˆ","LTV_ä»Šå¹´","LTV_å‰å¹´"]]
        comp = pd.merge(comp, ltv_c, on=["åº—èˆ—å","æœˆ"], how="left")

    # ã‚«ãƒ«ãƒ†æšæ•°
    if not card_df.empty:
        card_cur = card_df[card_df["å¹´"] == latest].rename(columns={"ã‚«ãƒ«ãƒ†æšæ•°":"ã‚«ãƒ«ãƒ†æšæ•°_ä»Šå¹´"})
        card_old = card_df[card_df["å¹´"] == prev].rename(columns={"ã‚«ãƒ«ãƒ†æšæ•°":"ã‚«ãƒ«ãƒ†æšæ•°_å‰å¹´"})
        card_c = pd.merge(card_cur, card_old, on=["åº—èˆ—å","æœˆ"], how="left")[["åº—èˆ—å","æœˆ","ã‚«ãƒ«ãƒ†æšæ•°_ä»Šå¹´","ã‚«ãƒ«ãƒ†æšæ•°_å‰å¹´"]]
        comp = pd.merge(comp, card_c, on=["åº—èˆ—å","æœˆ"], how="left")

    # å¢—æ¸›ç‡ï¼ˆå°æ•°1æ¡ï¼‰
    def _rate(a, b):
        den = b.replace(0, pd.NA) if isinstance(b, pd.Series) else (pd.NA if b==0 else b)
        return ((a - b) / den * 100).astype("Float64").round(1) if isinstance(den, pd.Series) else None

    comp["ç·å£²ä¸Šå¢—æ¸›ç‡%"]   = _rate(comp["ç·å£²ä¸Š_ä»Šå¹´"], comp["ç·å£²ä¸Š_å‰å¹´"])
    comp["ç·æ¥é™¢æ•°å¢—æ¸›ç‡%"] = _rate(comp["ç·æ¥é™¢æ•°_ä»Šå¹´"], comp["ç·æ¥é™¢æ•°_å‰å¹´"])
    comp["ä¿é™ºæ–°æ‚£å¢—æ¸›ç‡%"] = _rate(comp["ä¿é™ºæ–°æ‚£_ä»Šå¹´"], comp["ä¿é™ºæ–°æ‚£_å‰å¹´"])
    comp["è‡ªç”±æ–°æ‚£å¢—æ¸›ç‡%"] = _rate(comp["è‡ªç”±æ–°æ‚£_ä»Šå¹´"], comp["è‡ªç”±æ–°æ‚£_å‰å¹´"])
    if "LTV_ä»Šå¹´" in comp.columns and "LTV_å‰å¹´" in comp.columns:
        comp["LTVå¢—æ¸›ç‡%"] = _rate(comp["LTV_ä»Šå¹´"], comp["LTV_å‰å¹´"])
    if "ã‚«ãƒ«ãƒ†æšæ•°_ä»Šå¹´" in comp.columns and "ã‚«ãƒ«ãƒ†æšæ•°_å‰å¹´" in comp.columns:
        comp["ã‚«ãƒ«ãƒ†æšæ•°å¢—æ¸›ç‡%"] = _rate(comp["ã‚«ãƒ«ãƒ†æšæ•°_ä»Šå¹´"], comp["ã‚«ãƒ«ãƒ†æšæ•°_å‰å¹´"])

    # è¡¨ç¤ºåˆ—ï¼ˆåº—èˆ—åˆ¥ã®æ˜ç´°ï¼‰
    show = [
        "åº—èˆ—å","æœˆ",
        "ç·å£²ä¸Š_å‰å¹´","ç·å£²ä¸Š_ä»Šå¹´","ç·å£²ä¸Šå¢—æ¸›ç‡%",
        "ç·æ¥é™¢æ•°_å‰å¹´","ç·æ¥é™¢æ•°_ä»Šå¹´","ç·æ¥é™¢æ•°å¢—æ¸›ç‡%",
        "ä¿é™ºæ–°æ‚£_å‰å¹´","ä¿é™ºæ–°æ‚£_ä»Šå¹´","ä¿é™ºæ–°æ‚£å¢—æ¸›ç‡%",
        "è‡ªç”±æ–°æ‚£_å‰å¹´","è‡ªç”±æ–°æ‚£_ä»Šå¹´","è‡ªç”±æ–°æ‚£å¢—æ¸›ç‡%",
        "LTV_å‰å¹´","LTV_ä»Šå¹´","LTVå¢—æ¸›ç‡%",
        "ã‚«ãƒ«ãƒ†æšæ•°_å‰å¹´","ã‚«ãƒ«ãƒ†æšæ•°_ä»Šå¹´","ã‚«ãƒ«ãƒ†æšæ•°å¢—æ¸›ç‡%",
    ]
    detail_cols = [c for c in show if c in comp.columns]
    # â˜…è¿½åŠ ï¼šä¸Šã®ã‚µãƒãƒªãƒ¼ã®åˆ—é †ã‚’ä¿å­˜ï¼ˆä¸‹ã®ã€Œé›†è¨ˆå¯¾è±¡â€¦ä¸€è¦§ã€ã§å†åˆ©ç”¨ï¼‰
    st.session_state["cols_allstore_summary"] = detail_cols

    comp_disp = comp[detail_cols].sort_values(["åº—èˆ—å","æœˆ"])

    # åˆè¨ˆè¨ˆç®—ã«ä½¿ã†åˆ—ï¼ˆå¢—æ¸›ç‡ã¯é™¤å¤–ï¼‰
    sum_targets = [c for c in detail_cols if c not in ("åº—èˆ—å","æœˆ") and not str(c).endswith("å¢—æ¸›ç‡%")]

    # --- åº—èˆ—æ˜ç´°ï¼ˆå¢—æ¸›ç‡ä»¥å¤–ã¯æ•´æ•°ã‚«ãƒ³ãƒï¼‰
    comp_disp = fmt_comma_int(comp_disp, sum_targets)

    # --- æœˆã”ã¨ã®åˆè¨ˆï¼ˆæœˆåˆè¨ˆï¼‰
    agg_base = comp[["æœˆ"] + sum_targets].copy()
    mon_sum = agg_base.groupby("æœˆ", as_index=False).sum(numeric_only=True)
    for base in ["ç·å£²ä¸Š","ç·æ¥é™¢æ•°","ä¿é™ºæ–°æ‚£","è‡ªç”±æ–°æ‚£","LTV","ã‚«ãƒ«ãƒ†æšæ•°"]:
        a, b, r = f"{base}_ä»Šå¹´", f"{base}_å‰å¹´", f"{base}å¢—æ¸›ç‡%"
        if a in mon_sum.columns and b in mon_sum.columns:
            mon_sum[r] = _rate(mon_sum[a], mon_sum[b])
    mon_disp = mon_sum.copy()
    mon_disp.insert(0, "åº—èˆ—å", mon_disp["æœˆ"].astype(int).astype(str) + "æœˆåˆè¨ˆ")
    mon_disp = fmt_comma_int(mon_disp, [c for c in mon_disp.columns if c in sum_targets])
    mon_disp = mon_disp[detail_cols]

    # --- ç·åˆè¨ˆï¼ˆ= æœˆåˆè¨ˆã®åˆç®—ï¼‰
    total_raw = mon_sum[sum_targets].sum(numeric_only=True)
    total_rec = {"åº—èˆ—å":"ç·åˆè¨ˆ","æœˆ":"ç·è¨ˆ"}
    for k, v in total_raw.items():
        total_rec[k] = v
    for base in ["ç·å£²ä¸Š","ç·æ¥é™¢æ•°","ä¿é™ºæ–°æ‚£","è‡ªç”±æ–°æ‚£","LTV","ã‚«ãƒ«ãƒ†æšæ•°"]:
        a, b, r = f"{base}_ä»Šå¹´", f"{base}_å‰å¹´", f"{base}å¢—æ¸›ç‡%"
        if a in total_rec and b in total_rec:
            total_rec[r] = _rate(pd.Series([total_rec[a]]), pd.Series([total_rec[b]])).iloc[0]
    total_disp = pd.DataFrame([total_rec])
    total_disp = fmt_comma_int(total_disp, [c for c in sum_targets if c in total_disp.columns])
    total_disp = total_disp[detail_cols]

    final_disp = pd.concat([comp_disp, mon_disp, total_disp], ignore_index=True)
    st.dataframe(final_disp, use_container_width=True)
else:
    st.info("å…ˆã«ã€å£²ä¸Šç®¡ç†è¡¨ã€ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")

# 3) äºˆå®Ÿï¼ˆå£²ä¸Šãƒ»çµŒè²»ï¼šç›®æ¨™/å®Ÿç¸¾ï¼‰
st.header("ğŸ“ˆ äºˆå®Ÿï¼ˆå£²ä¸Šãƒ»çµŒè²»ï¼šç›®æ¨™/å®Ÿç¸¾ï¼‰")
files_yj = st.file_uploader("ğŸ“‚ äºˆå®Ÿç®¡ç†ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆã‚°ãƒ«ãƒ¼ãƒ—å˜ä½ãƒ»è¤‡æ•°å¯ï¼‰â€¦æ³¨æ„ï¼èª­ã¿å–ã‚Šã«10åˆ†ãã‚‰ã„ã‹ã‹ã‚Šã¾ã™", type=["xlsx"], accept_multiple_files=True, key="yj_files")
yj_df = load_yj(files_yj) if files_yj else pd.DataFrame()
# â‘¢ åº—åçµ±ä¸€ï¼ˆäºˆå®Ÿï¼‰
if not yj_df.empty:
    yj_df = unify_store_names(yj_df)
if yj_df.empty:
    st.caption("äºˆå®Ÿç®¡ç†ã®ãƒ–ãƒƒã‚¯ï¼ˆå„ã‚·ãƒ¼ãƒˆï¼åº—èˆ—ï¼‰ã‚’å…¥ã‚Œã‚‹ã¨ã€å¹´ãƒ»æœˆÃ—åº—èˆ—ã®ç›®æ¨™/å®Ÿç¸¾ï¼ˆå£²ä¸Šãƒ»çµŒè²»ï¼‰ã¨ç²—åˆ©ãŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚")
else:
    y_opts = sorted(yj_df["å¹´"].dropna().unique().tolist())
    c1, c2 = st.columns(2)
    with c1:
        sel_yj_y = st.selectbox("å¹´ï¼ˆäºˆå®Ÿï¼‰", y_opts, index=len(y_opts)-1)
    with c2:
        m_opts = sorted(yj_df.query("å¹´ == @sel_yj_y")["æœˆ"].dropna().unique().tolist())
        sel_yj_m = st.selectbox("æœˆï¼ˆäºˆå®Ÿï¼‰", m_opts, index=len(m_opts)-1 if m_opts else 0)

    yj_m = yj_df.query("å¹´ == @sel_yj_y & æœˆ == @sel_yj_m").copy()
    if not yj_m.empty:
        for c in ["ç²—åˆ©ç‡ç›®æ¨™", "ç²—åˆ©ç‡å®Ÿç¸¾"]:
            if c in yj_m.columns:
                yj_m[c] = pd.to_numeric(yj_m[c], errors="coerce").round(1)
        money_cols = ["å£²ä¸Šç›®æ¨™","å£²ä¸Šå®Ÿç¸¾","çµŒè²»ç›®æ¨™","çµŒè²»å®Ÿç¸¾","ç²—åˆ©ç›®æ¨™","ç²—åˆ©å®Ÿç¸¾"]
        yj_m = fmt_comma_int(yj_m, money_cols)
        show_cols = ["åº—èˆ—å","å£²ä¸Šç›®æ¨™","å£²ä¸Šå®Ÿç¸¾","çµŒè²»ç›®æ¨™","çµŒè²»å®Ÿç¸¾","ç²—åˆ©ç›®æ¨™","ç²—åˆ©ç‡ç›®æ¨™","ç²—åˆ©å®Ÿç¸¾","ç²—åˆ©ç‡å®Ÿç¸¾"]
        present = [c for c in show_cols if c in yj_m.columns]
        st.dataframe(yj_m[present].sort_values("å£²ä¸Šå®Ÿç¸¾", ascending=False, key=lambda s: pd.to_numeric(s.str.replace(",",""), errors="coerce")),
                     use_container_width=True)

    st.markdown("#### ğŸ“… æœˆã”ã¨ã®ä¸€è¦§ï¼ˆå¹´åˆè¨ˆã¤ãï¼‰")
# ---- æœˆã”ã¨ã®ä¸€è¦§ï¼ˆå¹´åˆè¨ˆã¤ãï¼‰â€»åˆè¨ˆè¡Œã¯åˆè¨ˆå€¤ã‹ã‚‰ç²—åˆ©ãƒ»ç²—åˆ©ç‡ã‚’å†è¨ˆç®— ----
    yj_y = yj_df.query("å¹´ == @sel_yj_y").copy()

    agg_cols = ["å£²ä¸Šç›®æ¨™", "å£²ä¸Šå®Ÿç¸¾", "çµŒè²»ç›®æ¨™", "çµŒè²»å®Ÿç¸¾"]
    mon = yj_y.groupby("æœˆ", as_index=False)[agg_cols].sum(numeric_only=True)

    # æœˆåˆ¥ã®ç²—åˆ©ãƒ»ç²—åˆ©ç‡
    mon["ç²—åˆ©ç›®æ¨™"]   = mon["å£²ä¸Šç›®æ¨™"] - mon["çµŒè²»ç›®æ¨™"]
    mon["ç²—åˆ©å®Ÿç¸¾"]   = mon["å£²ä¸Šå®Ÿç¸¾"] - mon["çµŒè²»å®Ÿç¸¾"]
    mon["ç²—åˆ©ç‡ç›®æ¨™"] = (mon["ç²—åˆ©ç›®æ¨™"] / mon["å£²ä¸Šç›®æ¨™"] * 100).where(mon["å£²ä¸Šç›®æ¨™"] != 0).round(1)
    mon["ç²—åˆ©ç‡å®Ÿç¸¾"] = (mon["ç²—åˆ©å®Ÿç¸¾"] / mon["å£²ä¸Šå®Ÿç¸¾"] * 100).where(mon["å£²ä¸Šå®Ÿç¸¾"] != 0).round(1)

    # --- åˆè¨ˆè¡Œï¼ˆç²—åˆ©ã¯ã€Œåˆè¨ˆå£²ä¸Š - åˆè¨ˆçµŒè²»ã€ã§å†è¨ˆç®—ã€ç²—åˆ©ç‡ã‚‚åˆè¨ˆã‹ã‚‰ç®—å‡ºï¼‰ ---
    tot_sales_goal   = mon["å£²ä¸Šç›®æ¨™"].sum()
    tot_sales_actual = mon["å£²ä¸Šå®Ÿç¸¾"].sum()
    tot_exp_goal     = mon["çµŒè²»ç›®æ¨™"].sum()
    tot_exp_actual   = mon["çµŒè²»å®Ÿç¸¾"].sum()

    tot_row = {
        "æœˆ": "åˆè¨ˆ",
        "å£²ä¸Šç›®æ¨™":   tot_sales_goal,
        "å£²ä¸Šå®Ÿç¸¾":   tot_sales_actual,
        "çµŒè²»ç›®æ¨™":   tot_exp_goal,
        "çµŒè²»å®Ÿç¸¾":   tot_exp_actual,
    }
    # ç²—åˆ©ï¼ˆåˆè¨ˆå€¤ã‹ã‚‰ç®—å‡ºï¼‰
    tot_row["ç²—åˆ©ç›®æ¨™"]   = tot_sales_goal   - tot_exp_goal
    tot_row["ç²—åˆ©å®Ÿç¸¾"]   = tot_sales_actual - tot_exp_actual
    # ç²—åˆ©ç‡ï¼ˆåˆè¨ˆå€¤ã‹ã‚‰ç®—å‡ºï¼‰
    tot_row["ç²—åˆ©ç‡ç›®æ¨™"] = round((tot_row["ç²—åˆ©ç›®æ¨™"] / tot_sales_goal   * 100), 1) if tot_sales_goal   else None
    tot_row["ç²—åˆ©ç‡å®Ÿç¸¾"] = round((tot_row["ç²—åˆ©å®Ÿç¸¾"] / tot_sales_actual * 100), 1) if tot_sales_actual else None

    mon_total = pd.concat([mon.sort_values("æœˆ"), pd.DataFrame([tot_row])], ignore_index=True)

    # è¡¨ç¤ºæ•´å½¢
    money_cols = ["å£²ä¸Šç›®æ¨™","å£²ä¸Šå®Ÿç¸¾","çµŒè²»ç›®æ¨™","çµŒè²»å®Ÿç¸¾","ç²—åˆ©ç›®æ¨™","ç²—åˆ©å®Ÿç¸¾"]
    mon_total = fmt_comma_int(mon_total, money_cols)
    # ç²—åˆ©ç‡åˆ—ã¯å°æ•°1æ¡ã®ã¾ã¾ï¼ˆNone ã¯ç©ºè¡¨ç¤ºã«ã—ãŸã„å ´åˆã¯ä¸‹è¨˜ã‚’ä½¿ç”¨ï¼‰
    for c in ["ç²—åˆ©ç‡ç›®æ¨™","ç²—åˆ©ç‡å®Ÿç¸¾"]:
        if c in mon_total.columns:
            mon_total[c] = mon_total[c].apply(lambda x: "" if pd.isna(x) else f"{x:.1f}")

    st.dataframe(mon_total, use_container_width=True, hide_index=True)


# 4) å€‹äººç”Ÿç”£æ€§ï¼ˆåº—èˆ—åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»è¤‡æ•°å¯¾å¿œï¼‰
st.header("ğŸ‘¤ å€‹äººç”Ÿç”£æ€§ï¼ˆåº—èˆ—åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»è¤‡æ•°å¯¾å¿œï¼‰")
files_person = st.file_uploader("ğŸ“‚ å€‹äººç”Ÿç”£æ€§ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå„åº—èˆ—ãƒ»å„æœˆã®ã‚·ãƒ¼ãƒˆï¼‰", type=["xlsx"], accept_multiple_files=True, key="person_files")
pp_df, pp_logs = load_person_productivity(files_person) if files_person else (pd.DataFrame(), [])
# â‘¢ åº—åçµ±ä¸€ï¼ˆå€‹äººç”Ÿç”£æ€§ï¼‰
if not pp_df.empty:
    pp_df = unify_store_names(pp_df)
if pp_logs:
    with st.expander("ğŸ“ å€‹äººç”Ÿç”£æ€§ èª­ã¿å–ã‚Šãƒ­ã‚°", expanded=False):
        for line in pp_logs:
            st.write(line)

if pp_df.empty:
    st.caption("å„ãƒ–ãƒƒã‚¯ã®æœˆã‚·ãƒ¼ãƒˆã‹ã‚‰ã€ç¨¼åƒæ•°ï¼ç›®æ¨™å€¤/æ—¥ï¼ç›®æ¨™å€¤/æœˆï¼é€²æ—ï¼é”æˆç‡ã€ã‚’èª­ã¿å–ã‚Šã¾ã™ã€‚")
else:
    # --- å¹´/æœˆå€™è£œã‚’æ­£è¦åŒ–ã—ã¦ä½œæˆ ---
    yser = pd.to_numeric(pp_df["å¹´"], errors="coerce")
    yser = yser[(yser >= 2000) & (yser <= 2100)].astype(int)
    mser = pd.to_numeric(pp_df["æœˆ"], errors="coerce")
    mser = mser[(mser >= 1) & (mser <= 12)].astype(int)

    year_opts  = sorted(yser.unique().tolist())
    month_opts = sorted(mser.unique().tolist())

    c1, c2 = st.columns(2)
    with c1:
        sel_year = st.selectbox(
            "å¹´ï¼ˆå€‹äººç”Ÿç”£æ€§ï¼‰",
            year_opts,
            index=len(year_opts)-1,
            key="pp_year_select_main"      # â† å›ºæœ‰ã‚­ãƒ¼
        )
    with c2:
        idx_m = len(month_opts) - 1 if month_opts else 0
        sel_month = st.selectbox(
            "æœˆï¼ˆå€‹äººç”Ÿç”£æ€§ï¼‰",
            month_opts,
            index=idx_m,
            key="pp_month_select_main",     # â† å›ºæœ‰ã‚­ãƒ¼
            disabled=(len(month_opts) == 0)
        )

    # --- ãƒ•ã‚£ãƒ«ã‚¿ï¼†è¡¨ç¤ºã¯ 1 å›ã ã‘ ---
    view = pp_df.query("å¹´ == @sel_year & æœˆ == @sel_month").copy()

    # === å€‹äººä¸€è¦§ã‚’ã€Œæ‹…å½“â‰ é™¢ã€ã¨ã€Œé™¢ã®ã¿ã€ã«åˆ†ã‘ã¦è¡¨ç¤ºï¼ˆæ´¾ç”Ÿåˆ—ãƒ•ãƒ«ç‰ˆï¼‰ ===
    def _ensure_pp_derived(df: pd.DataFrame) -> pd.DataFrame:
        """æ—¥å‰²å¹³å‡ / å¿…è¦ç¨¼åƒæ•° / å¿…è¦ç¨¼åƒæ•°ã®å·® / ä¸è¶³é‡‘é¡ / æ—¥å‰²é”æˆç‡ ã‚’é˜²å¼¾ã§è£œå®Œ"""
        import numpy as np
        num = lambda c: pd.to_numeric(df.get(c), errors="coerce")

        # æ—¥å‰²å¹³å‡ = é€²æ— Ã· ç¨¼åƒæ•°ï¼ˆæ•´æ•°ï¼‰
        if "æ—¥å‰²å¹³å‡" not in df.columns or df["æ—¥å‰²å¹³å‡"].isna().all():
            df["æ—¥å‰²å¹³å‡"] = (num("é€²æ—") / num("ç¨¼åƒæ•°")).round(0)

        # å¿…è¦ç¨¼åƒæ•° = ceil(ç›®æ¨™å€¤_æœˆ Ã· æ—¥å‰²å¹³å‡)ï¼ˆ0/NaNã¯NaNï¼‰
        if "å¿…è¦ç¨¼åƒæ•°" not in df.columns or df["å¿…è¦ç¨¼åƒæ•°"].isna().all():
            den = pd.to_numeric(df["æ—¥å‰²å¹³å‡"], errors="coerce")
            df["å¿…è¦ç¨¼åƒæ•°"] = np.ceil(num("ç›®æ¨™å€¤_æœˆ") / den)
            df.loc[~np.isfinite(df["å¿…è¦ç¨¼åƒæ•°"]), "å¿…è¦ç¨¼åƒæ•°"] = np.nan

        # å¿…è¦ç¨¼åƒæ•°ã®å·® = å¿…è¦ç¨¼åƒæ•° âˆ’ ç¨¼åƒæ•°ï¼ˆä¸è¶³åˆ†ã®ã¿ã€‚ãƒã‚¤ãƒŠã‚¹â†’0ï¼‰
        df["å¿…è¦ç¨¼åƒæ•°ã®å·®"] = (
            pd.to_numeric(df["å¿…è¦ç¨¼åƒæ•°"], errors="coerce") - num("ç¨¼åƒæ•°")
        ).clip(lower=0)

        # ä¸è¶³é‡‘é¡ = ç›®æ¨™å€¤_æœˆ âˆ’ é€²æ—ï¼ˆä¸è¶³åˆ†ã®ã¿ã€‚ãƒã‚¤ãƒŠã‚¹â†’0ï¼‰
        df["ä¸è¶³é‡‘é¡"] = (num("ç›®æ¨™å€¤_æœˆ") - num("é€²æ—")).clip(lower=0)

        # æ—¥å‰²é”æˆç‡ = æ—¥å‰²å¹³å‡ Ã· ç›®æ¨™å€¤_æ—¥ Ã—100ï¼ˆç„¡ã‘ã‚Œã°è£œå®Œï¼‰
        if "æ—¥å‰²é”æˆç‡" not in df.columns or df["æ—¥å‰²é”æˆç‡"].isna().all():
            df["æ—¥å‰²é”æˆç‡"] = (pd.to_numeric(df["æ—¥å‰²å¹³å‡"], errors="coerce") / num("ç›®æ¨™å€¤_æ—¥") * 100)

        # æœˆã®é”æˆç‡ã¯å¸¸ã«å†è¨ˆç®—ï¼ˆé€²æ— Ã· ç›®æ¨™å€¤_æœˆ Ã—100ï¼‰
        df["é”æˆç‡"] = (num("é€²æ—") / num("ç›®æ¨™å€¤_æœˆ") * 100)

        return df

    # è¡¨ç¤ºåˆ—ï¼ˆå€‹äººãƒ»é™¢ å…±é€šï¼‰
    show_cols = [
        "å¹´","æœˆ","åº—èˆ—å","æ‹…å½“",
        "ç¨¼åƒæ•°","å¿…è¦ç¨¼åƒæ•°","å¿…è¦ç¨¼åƒæ•°ã®å·®",
        "ç›®æ¨™å€¤_æ—¥","æ—¥å‰²å¹³å‡","æ—¥å‰²é”æˆç‡",
        "ç›®æ¨™å€¤_æœˆ","é€²æ—","ä¸è¶³é‡‘é¡","é”æˆç‡"
    ]
    money_cols = ["ç¨¼åƒæ•°","å¿…è¦ç¨¼åƒæ•°","å¿…è¦ç¨¼åƒæ•°ã®å·®","ç›®æ¨™å€¤_æ—¥","æ—¥å‰²å¹³å‡","ç›®æ¨™å€¤_æœˆ","é€²æ—","ä¸è¶³é‡‘é¡"]
    # â˜…è¿½åŠ ï¼šä¸Šã®å€‹äººç”Ÿç”£æ€§ã®åˆ—é †ã‚’ä¿å­˜ï¼ˆä¸‹ã®ã€Œåº—èˆ—Ã—æœˆ æŒ‡å®šã€ä¸€è¦§ã§å†åˆ©ç”¨ï¼‰
    st.session_state["cols_person_view"] = show_cols
    # -------- 1) æ‹…å½“ â‰  ã€Œé™¢ã€ --------
    staff = view.query("æ‹…å½“ != 'é™¢'").copy()
    if not staff.empty:
        staff = _ensure_pp_derived(staff)
        staff = fmt_comma_int(staff, money_cols)
        staff = fmt_percent(staff, ["é”æˆç‡", "æ—¥å‰²é”æˆç‡"])
        st.dataframe(
            staff[[c for c in show_cols if c in staff.columns]].sort_values(["åº—èˆ—å","æ‹…å½“"]),
            use_container_width=True, hide_index=True
        )
    else:
        st.info("æ‹…å½“ï¼ˆé™¢ä»¥å¤–ï¼‰ã®è¡Œã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

    # -------- 2) ã€Œé™¢ã€ã ã‘ --------
    inn = view.query("æ‹…å½“ == 'é™¢'").copy()
    if not inn.empty:
        st.markdown("##### é™¢ï¼ˆåˆè¨ˆï¼‰")
        inn = _ensure_pp_derived(inn)
        inn = fmt_comma_int(inn, money_cols)
        inn = fmt_percent(inn, ["é”æˆç‡", "æ—¥å‰²é”æˆç‡"])
        st.dataframe(
            inn[[c for c in show_cols if c in inn.columns]].sort_values(["åº—èˆ—å"]),
            use_container_width=True, hide_index=True
        )

    # === æœˆã”ã¨ã®ã‚µãƒãƒªï¼ˆé™¢ã®ã¿ï¼šç›®æ¨™å€¤_æœˆãƒ»é€²æ—ãƒ»é”æˆç‡ï¼‰ ==========================
    st.markdown("#### ğŸ—“ æœˆã”ã¨ã®ã‚µãƒãƒªï¼ˆé™¢ã®ã¿ï¼‰")
    base = pp_df.query("å¹´ == @sel_year & æ‹…å½“ == 'é™¢'").copy()
    if base.empty:
        st.info("ã“ã®å¹´ã®ã€é™¢ã€ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        m = pd.to_numeric(base["ç›®æ¨™å€¤_æœˆ"], errors="coerce")
        p = pd.to_numeric(base["é€²æ—"],      errors="coerce")
        g = base.assign(_m=m, _p=p)\
                .groupby("æœˆ", as_index=False)\
                .agg(ç›®æ¨™å€¤_æœˆ=("_m","sum"), é€²æ—=("_p","sum"))
        g["é”æˆç‡"] = (g["é€²æ—"] / g["ç›®æ¨™å€¤_æœˆ"] * 100)

        # åˆè¨ˆè¡Œï¼ˆåˆè¨ˆã‹ã‚‰å†è¨ˆç®—ï¼‰
        tot_m, tot_p = g["ç›®æ¨™å€¤_æœˆ"].sum(), g["é€²æ—"].sum()
        tot = {"æœˆ":"åˆè¨ˆ", "ç›®æ¨™å€¤_æœˆ":tot_m, "é€²æ—":tot_p,
               "é”æˆç‡": (tot_p / tot_m * 100) if tot_m else None}
        out = pd.concat([g, pd.DataFrame([tot])], ignore_index=True)

        out = fmt_comma_int(out, ["ç›®æ¨™å€¤_æœˆ","é€²æ—"])
        out = fmt_percent(out, ["é”æˆç‡"])
        st.dataframe(out[["æœˆ","ç›®æ¨™å€¤_æœˆ","é€²æ—","é”æˆç‡"]],
                     use_container_width=True, hide_index=True)

   

# 5) åº—èˆ—é¸æŠï¼ˆã‚·ãƒ³ãƒ—ãƒ«ï¼‰
# === ğŸª åº—èˆ—æƒ…å ±ï¼ˆKPIã‚«ãƒ¼ãƒ‰ï¼ç¨¼åƒÃ—åŠ¹ç‡ï¼æ¥é™¢ãƒ»é¡§å®¢ä¾¡å€¤ï¼‰ =========================
st.header("ğŸª åº—èˆ—æƒ…å ±")

# --- åº—èˆ—ã®å€™è£œï¼ˆã©ã®DFã«ã‚‚å‡ºã¦ãã‚‹åº—èˆ—ã‚’ã¾ã¨ã‚ã‚‹ï¼‰
stores_all = []
for _df in [sales_df, yj_df, pp_df]:
    if not _df.empty and "åº—èˆ—å" in _df.columns:
        stores_all.extend(_df["åº—èˆ—å"].dropna().astype(str).tolist())
stores_all = sorted(pd.unique(pd.Series(stores_all)))
if not stores_all:
    st.info("åº—èˆ—æƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹ã«ã¯ã€å…ˆã«å£²ä¸Šç®¡ç†ãƒ»äºˆå®Ÿãƒ»å€‹äººç”Ÿç”£æ€§ã®ã„ãšã‚Œã‹ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
else:
    c0, c1, c2 = st.columns([2,1,1])
    with c0:
        sel_store = st.selectbox("åº—èˆ—ã‚’é¸æŠï¼ˆåº—èˆ—æƒ…å ±ï¼‰", stores_all, key="store_info_select")


    # --- å¹´æœˆã®å€™è£œï¼šäºˆå®Ÿå„ªå…ˆâ†’å£²ä¸Šç®¡ç†â†’å€‹äººç”Ÿç”£æ€§ã‹ã‚‰æ¨å®š
    def _ym_opts(df):
        # None / ç©ºDF / å¿…é ˆã‚«ãƒ©ãƒ æ¬ è½ã¯ã‚¹ã‚­ãƒƒãƒ—
        if df is None or df.empty or not {"åº—èˆ—å", "å¹´", "æœˆ"}.issubset(df.columns):
            return []
        sub = df.loc[df["åº—èˆ—å"] == sel_store, ["å¹´", "æœˆ"]].copy()
        # æ•°å€¤åŒ–ã—ã¦ã‹ã‚‰æ¬ æã‚’é™¤å¤–
        sub["å¹´"] = pd.to_numeric(sub["å¹´"], errors="coerce")
        sub["æœˆ"] = pd.to_numeric(sub["æœˆ"], errors="coerce")
        sub = sub.dropna()
        # (å¹´, æœˆ) ã®ã‚¿ãƒ—ãƒ«ã«ã—ã¦è¿”å´ï¼ˆé‡è¤‡é™¤å»ï¼‰
        return list(set(zip(sub["å¹´"].astype(int), sub["æœˆ"].astype(int))))

    # â˜… ã“ã“ã‚’ â€œor é€£é–â€ ã§ã¯ãªãåˆé›†åˆã«å¤‰æ›´
    ym_set = set(_ym_opts(yj_df)) | set(_ym_opts(sales_df)) | set(_ym_opts(pp_df))
    ym = sorted(ym_set)  # [(å¹´, æœˆ), ...] ã‚’å¹´â†’æœˆã§æ˜‡é †

    c1, c2 = st.columns(2)

    if ym:
        # å®Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å€™è£œã‚’ä½œæˆï¼ˆå‰å›é¸æŠã‚’å„ªå…ˆï¼‰
        y_opts = sorted({y for y, _ in ym})
        prev_y = st.session_state.get("store_info_year")
        y_idx = y_opts.index(prev_y) if prev_y in y_opts else len(y_opts) - 1
        with c1:
            sel_year = st.selectbox("å¹´", y_opts, index=y_idx, key="store_info_year")

        m_opts = sorted({m for y, m in ym if y == sel_year})
        prev_m = st.session_state.get("store_info_month")
        m_idx = m_opts.index(prev_m) if prev_m in m_opts else len(m_opts) - 1
        with c2:
            sel_month = st.selectbox("æœˆ", m_opts, index=m_idx, key="store_info_month")
    else:
        # â˜…æœªèª­è¾¼ãªã©ã§å¹´æœˆãŒè¦‹ã¤ã‹ã‚‰ãªã„æ™‚ï¼šå®‰å…¨ãªãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§â€œç©ºè¡¨ç¤ºâ€
        y_fallback, m_fallback = safe_year_month_for_sales(
            st.session_state.get("store_info_year"),
            st.session_state.get("store_info_month"),
            sales_df if 'sales_df' in locals() else None
        )
        st.warning("ã“ã®åº—èˆ—ã®å¹´æœˆãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆæœªèª­è¾¼ã®å ´åˆã¯ç©ºè¡¨ç¤ºï¼‰ã€‚")
        with c1:
            sel_year  = st.selectbox("å¹´", [y_fallback], index=0, key="store_info_year", disabled=True)
        with c2:
            sel_month = st.selectbox("æœˆ", [m_fallback], index=0, key="store_info_month", disabled=True)


    
# ===================== ã‚»ã‚¯ã‚·ãƒ§ãƒ³1ï¼šæ‚£è€…åˆ†æï¼ˆå£²ä¸Šç®¡ç†è¡¨ ç”±æ¥ï¼‰ =====================
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # LTV / ã‚«ãƒ«ãƒ†æšæ•° / ç·å£²ä¸Š / ç·æ¥é™¢æ•°ï¼ˆå‰å¹´åŒæœˆæ¯”ã‚«ãƒ¼ãƒ‰ï¼‰
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    # 1) ãã®åº—èˆ—ã®ã€Œæœ€æ–°å¹´ï¼ˆlatestï¼‰Ã—é¸æŠæœˆï¼ˆsel_monthï¼‰ã€ã¨ã€Œå‰å¹´åŒæœˆã€ã‚’æƒãˆã‚‹
    # ã“ã“ã¯é¸æŠå€¤ã‚’ãã®ã¾ã¾ä½¿ã†ã€‚å¹´æœˆå€™è£œãŒç„¡ã„æ™‚ã ã‘ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚
    if ym:
        yr, mo = int(sel_year), int(sel_month)
    else:
        yr, mo = safe_year_month_for_sales(
            st.session_state.get("store_info_year"),
            st.session_state.get("store_info_month"),
            sales_df if 'sales_df' in locals() else None
        )
    
    prev = yr - 1

    def _pick(df, value_col):
        """ï¼ˆåº—èˆ—ãƒ»å¹´ãƒ»æœˆï¼‰ã§ 1 å€¤ã‚’å¼•ããƒ˜ãƒ«ãƒ‘ãƒ¼ã€‚ç„¡ã„å ´åˆ Noneã€‚"""
        try:
            v = df.query("åº—èˆ—å == @sel_store & å¹´ == @yr & æœˆ == @mo")[value_col].iloc[0]
            return float(v) if pd.notna(v) else None
        except Exception:
            return None

    def _pick_prev(df, value_col):
        try:
            v = df.query("åº—èˆ—å == @sel_store & å¹´ == @prev & æœˆ == @mo")[value_col].iloc[0]
            return float(v) if pd.notna(v) else None
        except Exception:
            return None

    # 2) å¿…è¦ãª4æŒ‡æ¨™ã®ã€Œä»Šå¹´/å‰å¹´ã€ã‚’å–å¾—
    #   LTV / ã‚«ãƒ«ãƒ†æšæ•° ã¯å…ƒã®é›†ç´„DFï¼ˆltv_df, card_dfï¼‰ã‹ã‚‰
    cur_ltv  = _pick(ltv_df,  "LTV")   if not ltv_df.empty  else None
    prv_ltv  = _pick_prev(ltv_df, "LTV") if not ltv_df.empty else None

    cur_card = _pick(card_df, "ã‚«ãƒ«ãƒ†æšæ•°")   if not card_df.empty else None
    prv_card = _pick_prev(card_df, "ã‚«ãƒ«ãƒ†æšæ•°") if not card_df.empty else None

    #   ç·å£²ä¸Š / ç·æ¥é™¢æ•° ã¯ sales_df ã‚’åº—èˆ—Ã—å¹´Ã—æœˆã§åˆç®—ã—ã¦åˆ©ç”¨
    agg_cols = [c for c in ["ç·å£²ä¸Š", "ç·æ¥é™¢æ•°", "ä¿é™ºæ–°æ‚£", "è‡ªç”±æ–°æ‚£"] if c in sales_df.columns]
    _sales_mon = (
        sales_df.groupby(["åº—èˆ—å","å¹´","æœˆ"], as_index=False)[agg_cols].sum(numeric_only=True)
    ) if (not sales_df.empty and agg_cols) else pd.DataFrame(columns=["åº—èˆ—å","å¹´","æœˆ"] + agg_cols)

    def _pick_sales(col):
        try:
            v = _sales_mon.query("åº—èˆ—å == @sel_store & å¹´ == @yr & æœˆ == @mo")[col].iloc[0]
            return float(v) if pd.notna(v) else None
        except Exception:
            return None

    def _pick_sales_prev(col):
        try:
            v = _sales_mon.query("åº—èˆ—å == @sel_store & å¹´ == @prev & æœˆ == @mo")[col].iloc[0]
            return float(v) if pd.notna(v) else None
        except Exception:
            return None

    cur_sales = _pick_sales("ç·å£²ä¸Š")
    prv_sales = _pick_sales_prev("ç·å£²ä¸Š")

    cur_vis   = _pick_sales("ç·æ¥é™¢æ•°")
    prv_vis   = _pick_sales_prev("ç·æ¥é™¢æ•°")

    # 3) ã‚«ãƒ¼ãƒ‰æç”»
    st.markdown("##### LTV / ã‚«ãƒ«ãƒ†æšæ•° / ç·å£²ä¸Š / ç·æ¥é™¢æ•°ï¼ˆå‰å¹´åŒæœˆæ¯”ï¼‰")
    c1, c2, c3, c4 = st.columns(4)
    _metric_card(c1, "LTV",        cur_ltv,  prv_ltv,  "å††")
    _metric_card(c2, "ã‚«ãƒ«ãƒ†æšæ•°",  cur_card, prv_card, "æš")
    _metric_card(c3, "ç·å£²ä¸Š",      cur_sales, prv_sales, "å††")
    _metric_card(c4, "ç·æ¥é™¢æ•°",    cur_vis,   prv_vis,   "äºº")
    def _pick_sales(col):
        try:
            v = _sales_mon.query("åº—èˆ—å == @sel_store & å¹´ == @yr & æœˆ == @mo")[col].iloc[0]
            return float(v) if pd.notna(v) else None
        except Exception:
            return None

    def _pick_sales_prev(col):
        try:
            v = _sales_mon.query("åº—èˆ—å == @sel_store & å¹´ == @prev & æœˆ == @mo")[col].iloc[0]
            return float(v) if pd.notna(v) else None
        except Exception:
            return None

    cur_ins = _pick_sales("ä¿é™ºæ–°æ‚£") if "ä¿é™ºæ–°æ‚£" in _sales_mon.columns else None
    prv_ins = _pick_sales_prev("ä¿é™ºæ–°æ‚£") if "ä¿é™ºæ–°æ‚£" in _sales_mon.columns else None
    cur_sp  = _pick_sales("è‡ªç”±æ–°æ‚£") if "è‡ªç”±æ–°æ‚£" in _sales_mon.columns else None
    prv_sp  = _pick_sales_prev("è‡ªç”±æ–°æ‚£") if "è‡ªç”±æ–°æ‚£" in _sales_mon.columns else None

    c5, c6 = st.columns(2)
    _metric_card(c5, "ä¿é™ºæ–°æ‚£", cur_ins, prv_ins, "äºº")
    _metric_card(c6, "è‡ªç”±æ–°æ‚£", cur_sp,  prv_sp,  "äºº")

    # ========== æœˆã”ã¨ã®å‰å¹´æ¯”è¼ƒï¼ˆç·å£²ä¸Šãƒ»ç·æ¥é™¢æ•°ãƒ»ä¿é™ºæ–°æ‚£ãƒ»è‡ªç”±æ–°æ‚£ï¼šæ¨ªä¸¦ã³ï¼‰ ==========
    st.markdown("### ğŸ“ˆ æœˆã”ã¨ã®å‰å¹´æ¯”è¼ƒ")

    if (_sales_mon is None) or _sales_mon.empty or (sel_store is None):
        st.info("å£²ä¸Šç®¡ç†ã®æœˆæ¬¡é›†è¨ˆãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
    else:
        latest_year = int(_sales_mon[_sales_mon["åº—èˆ—å"] == sel_store]["å¹´"].max())
        prev_year   = latest_year - 1

        metric_defs = [
            ("ç·å£²ä¸Š",   "ç·å£²ä¸Š",   "å††"),
            ("ç·æ¥é™¢æ•°", "ç·æ¥é™¢æ•°", "äºº"),
            ("ä¿é™ºæ–°æ‚£", "ä¿é™ºæ–°æ‚£", "äºº"),
            ("è‡ªç”±æ–°æ‚£", "è‡ªç”±æ–°æ‚£", "äºº"),
        ]
        metrics = [(k, t, u) for (k, t, u) in metric_defs if k in _sales_mon.columns]

        if not metrics:
            st.info("æ¯”è¼ƒå¯èƒ½ãªæŒ‡æ¨™ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆç·å£²ä¸Š / ç·æ¥é™¢æ•° / ä¿é™ºæ–°æ‚£ / è‡ªç”±æ–°æ‚£ ã®åˆ—ãŒä¸è¶³ï¼‰ã€‚")
        else:
            import altair as alt

            def yoy_grouped(metric_col: str, title: str, unit: str):
                base = _sales_mon.query(
                    "åº—èˆ—å == @sel_store and å¹´ in (@latest_year, @prev_year)"
                )[["å¹´", "æœˆ", metric_col]].copy()

                base[metric_col] = pd.to_numeric(base[metric_col], errors="coerce").fillna(0)
                base["å¹´"] = base["å¹´"].astype(str)  # è‰²ãƒ»ã‚ªãƒ•ã‚»ãƒƒãƒˆç”¨ã«æ–‡å­—åˆ—åŒ–
                month_order = list(range(1, 12 + 1))

                chart = (
                    alt.Chart(base)
                    .mark_bar()
                    .encode(
                        x=alt.X("æœˆ:O", title="æœˆ", sort=month_order, axis=alt.Axis(labelAngle=0)),
                        # â† å¹´ã”ã¨ã®æ£’ã‚’æ¨ªã«ãšã‚‰ã™ï¼ˆã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã®ã‚­ãƒ¢ï¼‰
                        xOffset=alt.XOffset("å¹´:N"),
                        color=alt.Color("å¹´:N", title="å¹´åº¦"),
                        y=alt.Y(f"{metric_col}:Q", title=f"{title}ï¼ˆ{unit}ï¼‰"),
                        tooltip=[
                            alt.Tooltip("å¹´:N", title="å¹´åº¦"),
                            alt.Tooltip("æœˆ:O", title="æœˆ"),
                            alt.Tooltip(f"{metric_col}:Q", title=title, format=",.0f"),
                        ],
                    )
                    .properties(height=260)
                )

                st.altair_chart(chart, use_container_width=True)

            rows = [metrics[i:i+2] for i in range(0, len(metrics), 2)]
            for row in rows:
                cols = st.columns(len(row))
                for (col, (mkey, mtitle, unit)) in zip(cols, row):
                    with col:
                        yoy_grouped(mkey, mtitle, unit)
    # ========== é›†è¨ˆå¯¾è±¡ å…¨åº—èˆ—ã‚µãƒãƒªãƒ¼ï¼ˆä»Šå¹´ vs å‰å¹´ï¼šæœˆÃ—åº—èˆ—ï¼‰ ==========
    st.markdown("### ğŸ§¾ é›†è¨ˆå¯¾è±¡ã«ãªã£ãŸ å…¨åº—èˆ—ã‚µãƒãƒªãƒ¼ï¼ˆä»Šå¹´ vs å‰å¹´ï¼‰")

    if ('_sales_mon' not in locals()) or _sales_mon is None or _sales_mon.empty:
        st.info("å£²ä¸Šç®¡ç†ã®æœˆæ¬¡é›†è¨ˆãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
    else:
        # ç›´è¿‘ã®å¹´ã‚’è»¸ã«å‰å¹´æ¯”è¼ƒ
        latest_year_all = int(_sales_mon["å¹´"].max())
        prev_year_all   = latest_year_all - 1

        # ä½¿ã†åŸºæœ¬æŒ‡æ¨™ï¼ˆå­˜åœ¨ã™ã‚‹ã‚‚ã®ã ã‘ï¼‰
        base_cols = [c for c in ["ç·å£²ä¸Š","ç·æ¥é™¢æ•°","ä¿é™ºæ–°æ‚£","è‡ªç”±æ–°æ‚£"] if c in _sales_mon.columns]

        cur = _sales_mon.query("å¹´ == @latest_year_all")[["åº—èˆ—å","æœˆ"] + base_cols].copy()
        prv = _sales_mon.query("å¹´ == @prev_year_all")[["åº—èˆ—å","æœˆ"] + base_cols].copy()
        cur = cur.add_suffix("_ä»Šå¹´").rename(columns={"åº—èˆ—å_ä»Šå¹´":"åº—èˆ—å","æœˆ_ä»Šå¹´":"æœˆ"})
        prv = prv.add_suffix("_å‰å¹´").rename(columns={"åº—èˆ—å_å‰å¹´":"åº—èˆ—å","æœˆ_å‰å¹´":"æœˆ"})

        comp = pd.merge(cur, prv, on=["åº—èˆ—å","æœˆ"], how="outer")

        # LTV / ã‚«ãƒ«ãƒ†æšæ•°ï¼ˆä¸Šæ®µã¨åŒã˜è¦é ˜ã§çµåˆï¼šã‚ã‚Œã°ä»˜ä¸ï¼‰
        if 'ltv_df' in locals() and ltv_df is not None and not ltv_df.empty:
            ltv_c = (ltv_df[ltv_df["å¹´"]==latest_year_all][["åº—èˆ—å","æœˆ","LTV"]]
                    .rename(columns={"LTV":"LTV_ä»Šå¹´"}))
            ltv_p = (ltv_df[ltv_df["å¹´"]==prev_year_all][["åº—èˆ—å","æœˆ","LTV"]]
                    .rename(columns={"LTV":"LTV_å‰å¹´"}))
            comp = comp.merge(ltv_c, on=["åº—èˆ—å","æœˆ"], how="left").merge(ltv_p, on=["åº—èˆ—å","æœˆ"], how="left")

        if 'card_df' in locals() and card_df is not None and not card_df.empty:
            cd_c = (card_df[card_df["å¹´"]==latest_year_all][["åº—èˆ—å","æœˆ","ã‚«ãƒ«ãƒ†æšæ•°"]]
                    .rename(columns={"ã‚«ãƒ«ãƒ†æšæ•°":"ã‚«ãƒ«ãƒ†æšæ•°_ä»Šå¹´"}))
            cd_p = (card_df[card_df["å¹´"]==prev_year_all][["åº—èˆ—å","æœˆ","ã‚«ãƒ«ãƒ†æšæ•°"]]
                    .rename(columns={"ã‚«ãƒ«ãƒ†æšæ•°":"ã‚«ãƒ«ãƒ†æšæ•°_å‰å¹´"}))
            comp = comp.merge(cd_c, on=["åº—èˆ—å","æœˆ"], how="left").merge(cd_p, on=["åº—èˆ—å","æœˆ"], how="left")

        # å¢—æ¸›ç‡ï¼ˆä¸Šæ®µã¨åŒã˜é–¢æ•°ã§OKï¼‰
        def _rate(a, b):
            a = pd.to_numeric(a, errors="coerce")
            b = pd.to_numeric(b, errors="coerce")
            den = b.replace(0, pd.NA)
            return ((a - b) / den * 100).astype("Float64").round(1)

        for base in ["ç·å£²ä¸Š","ç·æ¥é™¢æ•°","ä¿é™ºæ–°æ‚£","è‡ªç”±æ–°æ‚£","LTV","ã‚«ãƒ«ãƒ†æšæ•°"]:
            a, p = f"{base}_ä»Šå¹´", f"{base}_å‰å¹´"
            if (a in comp.columns) and (p in comp.columns):
                comp[f"{base}å¢—æ¸›ç‡%"] = _rate(comp[a], comp[p])

        # ---- é¸æŠåº—èˆ—ã ã‘ã«çµã‚‹ï¼ˆåº—èˆ—æƒ…å ±ã‚»ãƒ¬ã‚¯ã‚¿ã¨é€£å‹•ï¼‰ ----
        sel_store = st.session_state.get("store_info_select", st.session_state.get("info_store"))
        if sel_store:
            comp = comp[comp["åº—èˆ—å"] == sel_store]

        # ä¸Šæ®µã‚µãƒãƒªãƒ¼ã®åˆ—é †ã«æƒãˆã‚‹ï¼ˆå­˜åœ¨ã™ã‚‹åˆ—ã®ã¿ï¼‰
        cols_all = st.session_state.get("cols_allstore_summary")
        if cols_all:
            comp = comp.reindex(columns=[c for c in cols_all if c in comp.columns])

        # é‡‘é¡ãƒ»ä»¶æ•°ã¯ã‚«ãƒ³ãƒæ•´å½¢ï¼ˆâ€œ_ä»Šå¹´/å‰å¹´â€ã§çµ‚ã‚ã‚‹åˆ—ï¼‰
        money_like = [c for c in comp.columns
                    if (c.endswith("_ä»Šå¹´") or c.endswith("_å‰å¹´")) and (not c.endswith("å¢—æ¸›ç‡%"))]
        comp_disp = fmt_comma_int(comp.copy(), money_like)

        st.dataframe(comp_disp.sort_values(["åº—èˆ—å","æœˆ"]),
                    use_container_width=True, hide_index=True)


    st.markdown("### ğŸ‘¥ æ‚£è€…åˆ†æ")

# ã“ã®åº—èˆ—ã§æ‚£è€…åˆ†æDFã«å­˜åœ¨ã™ã‚‹æœ€æ–°å¹´ã‚’æ±ºå®š
    years_in_pa = []
    for _df in (gender_df, reason_df, age_df):
        if not _df.empty:
            years_in_pa.extend(
                _df.query("åº—èˆ—å == @sel_store")["å¹´"].dropna().astype(int).tolist()
            )
    if years_in_pa:
        latest = max(years_in_pa)
        prev   = latest - 1
    else:
        latest = int(sel_year); prev = latest - 1  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

    # æœ€æ–°å¹´ã®æ§‹æˆï¼ˆæ¨ªæ£’ï¼‹å‰²åˆ%ï¼‰â€” app - ã‚³ãƒ”ãƒ¼.py ã¨åŒã˜è¦‹ãŸç›®
    c1, c2, c3 = st.columns(3)
    with c1: plot_pivot(gender_df, sel_store, latest, "ç”·å¥³æ¯”ç‡")
    with c2: plot_pivot(reason_df, sel_store, latest, "æ¥é™¢å‹•æ©Ÿ")
    with c3: plot_pivot(age_df,    sel_store, latest, "å¹´é½¢æ¯”ç‡")

    # å‰å¹´ vs ä»Šå¹´ï¼ˆæ£’ã®æ¯”è¼ƒï¼‹å¢—æ¸›ãƒ†ãƒ¼ãƒ–ãƒ«ï¼‰
    st.markdown("#### ğŸ“Š å‰å¹´æ¯”è¼ƒ")
    plot_cat_yoy(reason_df, sel_store, latest, prev, "æ¥é™¢å‹•æ©Ÿ")
    plot_cat_yoy(gender_df, sel_store, latest, prev, "ç”·å¥³æ¯”ç‡")
    plot_cat_yoy(age_df,    sel_store, latest, prev, "å¹´é½¢æ¯”ç‡")
# =============================
# â‘  äºˆå®Ÿï¼ˆã‚«ãƒ¼ãƒ‰è¡¨ç¤ºï¼šåº—èˆ—Ã—å¹´æœˆï¼‰
# =============================
st.subheader("â‘  äºˆå®Ÿï¼ˆåº—èˆ—Ã—æœˆ æŒ‡å®šï¼šã‚«ãƒ¼ãƒ‰ï¼‰")

if 'yj_df' not in locals():
    st.info("äºˆå®Ÿãƒ‡ãƒ¼ã‚¿ãŒæœªèª­è¾¼ã§ã™ã€‚ä¸Šéƒ¨ã®ã€äºˆå®Ÿç®¡ç†ãƒ•ã‚¡ã‚¤ãƒ«ã€ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
else:
    if yj_df.empty:
        st.info("äºˆå®Ÿãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚")
    else:
        # åº—èˆ—æƒ…å ±ã®ã‚»ãƒ¬ã‚¯ã‚¿ã¨é€£å‹•
        kpi_store = st.session_state.get("store_info_select")
        kpi_year  = st.session_state.get("store_info_year")
        kpi_month = st.session_state.get("store_info_month")

        # å¿µã®ãŸã‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆåˆå›èª­ã¿è¾¼ã¿æ™‚ãªã©ï¼‰
        if kpi_store is None:
            kpi_store = sorted(yj_df["åº—èˆ—å"].dropna().unique().tolist())[0]
        if kpi_year is None:
            kpi_year = int(yj_df["å¹´"].dropna().max())
        if kpi_month is None:
            kpi_month = int(yj_df.query("å¹´ == @kpi_year")["æœˆ"].dropna().max())

        yj_one = yj_df.query("åº—èˆ—å == @kpi_store & å¹´ == @kpi_year & æœˆ == @kpi_month").copy()
        if yj_one.empty:
            st.warning("è©²å½“ã™ã‚‹äºˆå®Ÿãƒ¬ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            # è¤‡æ•°è¡Œã‚ã£ã¦ã‚‚åˆç®—ï¼ˆå®‰å…¨ï¼‰
            s_goal  = pd.to_numeric(yj_one.get("å£²ä¸Šç›®æ¨™"), errors="coerce").sum()
            s_act   = pd.to_numeric(yj_one.get("å£²ä¸Šå®Ÿç¸¾"), errors="coerce").sum()
            e_goal  = pd.to_numeric(yj_one.get("çµŒè²»ç›®æ¨™"), errors="coerce").sum()
            e_act   = pd.to_numeric(yj_one.get("çµŒè²»å®Ÿç¸¾"), errors="coerce").sum()
            g_goal  = s_goal - e_goal
            g_act   = s_act - e_act

            def _rate(act, goal):
                if pd.isna(goal) or goal == 0: return None
                return float(act) / float(goal) * 100.0

            r_sales = _rate(s_act, s_goal)
            r_exp   = _rate(e_act, e_goal)
            r_gross = _rate(g_act, g_goal)

            def _fmt_int(v): 
                return "" if pd.isna(v) else f"{int(round(v)):,}"
            def _fmt_pct(v):
                return "" if (v is None or pd.isna(v)) else f"{v:.1f}%"

            col1, col2, col3 = st.columns(3)

            with col1:
                st.markdown("##### å£²ä¸Š")
                st.metric(
                    label=f"ç›®æ¨™ {_fmt_int(s_goal)} å††",
                    value=f"{_fmt_int(s_act)} å††",
                    delta=f"é”æˆç‡ {_fmt_pct(r_sales)}",
                    delta_color="normal" if (r_sales or 0) >= 100 else "inverse"
                )

            with col2:
                st.markdown("##### çµŒè²»")
                st.metric(
                    label=f"ç›®æ¨™ {_fmt_int(e_goal)} å††",
                    value=f"{_fmt_int(e_act)} å††",
                    delta=f"é”æˆç‡ {_fmt_pct(r_exp)}",
                    # çµŒè²»ã¯â€œä½ã„ã»ã©è‰¯ã„â€ã ãŒã€ã“ã“ã¯é”æˆç‡ã®è¡¨ç¤ºãƒ«ãƒ¼ãƒ«ã«åˆã‚ã›ã¦é€šå¸¸è‰²
                    delta_color="normal" if (r_exp or 0) <= 100 else "inverse"
                )

            with col3:
                st.markdown("##### ç²—åˆ©")
                st.metric(
                    label=f"ç›®æ¨™ {_fmt_int(g_goal)} å††",
                    value=f"{_fmt_int(g_act)} å††",
                    delta=f"é”æˆç‡ {_fmt_pct(r_gross)}",
                    delta_color="normal" if (r_gross or 0) >= 100 else "inverse"
                )


    # ===================================
    # â‘¡ å€‹äººç”Ÿç”£ï¼ˆä¸€è¦§ï¼šåº—èˆ—Ã—å¹´æœˆ ã®æ‹…å½“è€…åˆ¥ï¼‰
    # ===================================
    st.subheader("â‘¡ å€‹äººç”Ÿç”£ï¼ˆåº—èˆ—Ã—æœˆ æŒ‡å®šï¼šæ‹…å½“è€…åˆ¥ä¸€è¦§ï¼‰")

    if 'pp_df' not in locals():
        st.info("å€‹äººç”Ÿç”£ãƒ‡ãƒ¼ã‚¿ãŒæœªèª­è¾¼ã§ã™ã€‚ä¸Šéƒ¨ã®ã€å€‹äººç”Ÿç”£æ€§ãƒ•ã‚¡ã‚¤ãƒ«ã€ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
    else:
        if pp_df.empty:
            st.info("å€‹äººç”Ÿç”£ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚")
        else:
            # åº—èˆ—æƒ…å ±ã®ã‚»ãƒ¬ã‚¯ã‚¿ã¨é€£å‹•
            kpi_store_pp = st.session_state.get("store_info_select")
            kpi_year_pp  = st.session_state.get("store_info_year")
            kpi_month_pp = st.session_state.get("store_info_month")

            # å¿µã®ãŸã‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            if kpi_store_pp is None:
                kpi_store_pp = sorted(pp_df["åº—èˆ—å"].dropna().unique().tolist())[0]
            if kpi_year_pp is None:
                kpi_year_pp = int(pp_df["å¹´"].dropna().max())
            if kpi_month_pp is None:
                kpi_month_pp = int(pp_df.query("å¹´ == @kpi_year_pp")["æœˆ"].dropna().max())

            view = pp_df.query(
                "åº—èˆ—å == @kpi_store_pp & å¹´ == @kpi_year_pp & æœˆ == @kpi_month_pp"
            ).copy()

            if view.empty:
                st.warning("è©²å½“ã™ã‚‹å€‹äººç”Ÿç”£ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            else:
                # äº’æ›å¯¾å¿œï¼šæ˜”ã®åˆ—åãŒæ¥ãŸã‚‰æƒãˆã‚‹
                if "ä¸è¶³ç¨¼åƒæ•°" in view.columns and "å¿…è¦ç¨¼åƒæ•°ã®å·®" not in view.columns:
                    view = view.rename(columns={"ä¸è¶³ç¨¼åƒæ•°": "å¿…è¦ç¨¼åƒæ•°ã®å·®"})

                # ä¸Šã®å€‹äººç”Ÿç”£æ€§ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§å®šç¾©ã—ãŸè£œå®Œé–¢æ•°ã‚’å†åˆ©ç”¨
                view = _ensure_pp_derived(view)

                # è¡¨ç¤ºæ•´å½¢ï¼ˆæ•°å€¤ â†’ ã‚«ãƒ³ãƒã€ï¼… â†’ xx.xï¼‰
                money_cols = [
                    "ç¨¼åƒæ•°","å¿…è¦ç¨¼åƒæ•°","å¿…è¦ç¨¼åƒæ•°ã®å·®",
                    "ç›®æ¨™å€¤_æ—¥","æ—¥å‰²å¹³å‡","ç›®æ¨™å€¤_æœˆ","é€²æ—","ä¸è¶³é‡‘é¡"
                ]
                view = fmt_comma_int(view, [c for c in money_cols if c in view.columns])
                view = fmt_percent(view, ["é”æˆç‡", "æ—¥å‰²é”æˆç‡"])

                # åˆ—é †ã¯â€œä¸Šã®å€‹äººç”Ÿç”£æ€§â€ã¨åŒã˜ã«ã™ã‚‹ï¼ˆä¿å­˜æ¸ˆã¿ï¼‰
                cols_pp = st.session_state.get("cols_person_view")
                if cols_pp:
                    show_cols = [c for c in cols_pp if c in view.columns]
                else:
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆåŸºæœ¬åŒã˜ä¸¦ã³ï¼‰
                    show_cols = [
                        "å¹´","æœˆ","åº—èˆ—å","æ‹…å½“",
                        "ç¨¼åƒæ•°","å¿…è¦ç¨¼åƒæ•°","å¿…è¦ç¨¼åƒæ•°ã®å·®",
                        "ç›®æ¨™å€¤_æ—¥","æ—¥å‰²å¹³å‡","æ—¥å‰²é”æˆç‡",
                        "ç›®æ¨™å€¤_æœˆ","é€²æ—","ä¸è¶³é‡‘é¡","é”æˆç‡"
                    ]
                    show_cols = [c for c in show_cols if c in view.columns]

                st.dataframe(
                    view[show_cols].sort_values(["åº—èˆ—å","æ‹…å½“"]),
                    use_container_width=True, hide_index=True
                )
