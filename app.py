import streamlit as st
import pandas as pd
import altair as alt
import re, math
from typing import List, Tuple

st.set_page_config(page_title="å£²ä¸Šãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰", layout="wide")
st.title("ğŸ“ Excelã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ â†’ å‰å¹´åŒæœˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. Helper
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_store_name(fname: str) -> str:
    m = re.match(r"\d+[._](.+?)\s", fname)
    if not m:
        raise ValueError("åº—èˆ—åãŒè§£æã§ãã¾ã›ã‚“")
    return m.group(1).strip()


def infer_year_month(df: pd.DataFrame) -> Tuple[int, int]:
    df["æ—¥ä»˜"] = pd.to_datetime(df["æ—¥ä»˜"], errors="coerce")
    valid = df["æ—¥ä»˜"].dropna()
    if valid.empty:
        raise ValueError("æ—¥ä»˜åˆ—ãŒã‚ã‚Šã¾ã›ã‚“")
    return int(valid.dt.year.mode()[0]), int(valid.dt.month.mode()[0])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. æ‚£è€…åˆ†æã‚·ãƒ¼ãƒˆãƒ‘ãƒ¼ã‚¹
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def parse_patient_analysis(f):
    sheet = pd.read_excel(f, sheet_name="æ‚£è€…åˆ†æ", header=None, engine="openpyxl")

    def _grab(keyword):
        idx_mask = sheet.apply(lambda r: r.astype(str).str.contains(keyword).any(), axis=1)
        if not idx_mask.any():
            return pd.DataFrame()
        r = idx_mask.idxmax()
        header = sheet.loc[r + 1].dropna()
        if header.empty:
            return pd.DataFrame()
        vals = sheet.loc[r + 2, header.index]
        return pd.DataFrame({"ã‚«ãƒ†ã‚´ãƒª": header.values, "ä»¶æ•°": pd.to_numeric(vals, errors="coerce").fillna(0)})

    gender = _grab("ç”·å¥³æ¯”ç‡")
    reason = _grab("æ¥é™¢å‹•æ©Ÿ")
    age    = _grab("å¹´é½¢æ¯”ç‡")
    return gender, reason, age

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. LTV ãƒ‘ãƒ¼ã‚¹
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def parse_ltv(f):
    df = pd.read_excel(f, sheet_name="åº—èˆ—åˆ†æ", header=None, engine="openpyxl")
    mask = df.apply(lambda r: r.astype(str).str.contains("LTV").any(), axis=1)
    if not mask.any():
        return None
    nums = pd.to_numeric(df[mask].iloc[0], errors="coerce").dropna()
    return float(nums.iloc[0]) if not nums.empty else None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒ¼ãƒ‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@st.cache_data(show_spinner=False)
def load(files):
    sales, reasons, genders, ages, ltvs = [], [], [], [], []
    for f in files:
        try:
            store = get_store_name(f.name)
        except ValueError as e:
            st.warning(str(e)); continue

        try:
            df_sales = pd.read_excel(f, sheet_name="å£²ä¸Šç®¡ç†", header=4, engine="openpyxl")
        except Exception as e:
            st.warning(f"{f.name}: å£²ä¸Šã‚·ãƒ¼ãƒˆèª­è¾¼å¤±æ•— {e}"); continue

        for col in ["ç·å£²ä¸Š", "ç·æ¥é™¢æ•°"]:
            if col in df_sales.columns:
                df_sales[col] = pd.to_numeric(df_sales[col], errors="coerce").fillna(0)

        try:
            y, m = infer_year_month(df_sales)
        except ValueError as e:
            st.warning(f"{f.name}: {e}"); continue

        df_sales["åº—èˆ—å"], df_sales["å¹´"], df_sales["æœˆ"] = store, y, m
        sales.append(df_sales)

        try:
            g, r, a = parse_patient_analysis(f)
            for _df in (g, r, a):
                if not _df.empty:
                    _df["åº—èˆ—å"], _df["å¹´"], _df["æœˆ"] = store, y, m
            if not r.empty: reasons.append(r)
            if not g.empty: genders.append(g)
            if not a.empty: ages.append(a)
        except Exception as e:
            st.warning(f"{f.name}: æ‚£è€…åˆ†æãƒ‘ãƒ¼ã‚¹å¤±æ•— {e}")

        val = parse_ltv(f)
        if val is not None:
            ltvs.append({"åº—èˆ—å": store, "å¹´": y, "æœˆ": m, "LTV": val})

    return (
        pd.concat(sales,   ignore_index=True) if sales   else pd.DataFrame(),
        pd.concat(reasons, ignore_index=True) if reasons else pd.DataFrame(),
        pd.concat(genders, ignore_index=True) if genders else pd.DataFrame(),
        pd.concat(ages,    ignore_index=True) if ages    else pd.DataFrame(),
        pd.DataFrame(ltvs),
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5. UI: ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

files = st.file_uploader("ğŸ“‚ è¤‡æ•°åº—èˆ—ã® Excel ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰", type="xlsx", accept_multiple_files=True)
if not files:
    st.info("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
    st.stop()

sales_df, reason_df, gender_df, age_df, ltv_df = load(files)
if sales_df.empty:
    st.error("æœ‰åŠ¹ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“"); st.stop()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 6. å…¨åº—èˆ—ã‚µãƒãƒªãƒ¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

monthly = (sales_df.groupby(["åº—èˆ—å", "å¹´", "æœˆ"], as_index=False)[["ç·å£²ä¸Š", "ç·æ¥é™¢æ•°"]].sum())
latest, prev = monthly["å¹´"].max(), monthly["å¹´"].max()-1
this_y, prev_y = monthly[monthly["å¹´"]==latest], monthly[monthly["å¹´"]==prev]
comp = pd.merge(this_y, prev_y, on=["åº—èˆ—å", "æœˆ"], how="left", suffixes=("_ä»Šå¹´", "_å‰å¹´"))
for k in ["ç·å£²ä¸Š", "ç·æ¥é™¢æ•°"]:
    comp[f"{k}å¢—æ¸›ç‡%"] = ((comp[f"{k}_ä»Šå¹´"]-comp[f"{k}_å‰å¹´"])/comp[f"{k}_å‰å¹´"].replace(0,pd.NA)*100).round(1)

# LTV merge
if not ltv_df.empty:
    ltv_this = ltv_df[ltv_df["å¹´"]==latest]
    ltv_prev = ltv_df[ltv_df["å¹´"]==prev]
    ltv_cmp  = pd.merge(ltv_this, ltv_prev, on=["åº—èˆ—å", "æœˆ"], how="left", suffixes=("_ä»Šå¹´","_å‰å¹´"))
    ltv_cmp["LTVå¢—æ¸›ç‡%"] = ((ltv_cmp["LTV_ä»Šå¹´"]-ltv_cmp["LTV_å‰å¹´"])/ltv_cmp["LTV_å‰å¹´"].replace(0,pd.NA)*100).round(1)
    comp = pd.merge(comp, ltv_cmp[["åº—èˆ—å","æœˆ","LTV_å‰å¹´","LTV_ä»Šå¹´","LTVå¢—æ¸›ç‡%"]], on=["åº—èˆ—å","æœˆ"], how="left")

# åˆè¨ˆè¡Œ
num_cols = [c for c in comp.columns if any(k in c for k in ["ç·å£²ä¸Š_","ç·æ¥é™¢æ•°_","LTV_"])]
rows=[]
for m in sorted(comp["æœˆ"].unique()):
    sub=comp[comp["æœˆ"]==m]
    if sub.empty: continue
    d={"åº—èˆ—å":"åˆè¨ˆ","æœˆ":m}
    for c in num_cols: d[c]=sub[c].sum()
    if d.get("ç·å£²ä¸Š_å‰å¹´",0): d["ç·å£²ä¸Šå¢—æ¸›ç‡%"]=((d["ç·å£²ä¸Š_ä»Šå¹´"]-d["ç·å£²ä¸Š_å‰å¹´"])/d["ç·å£²ä¸Š_å‰å¹´"]*100).round(1)
    if d.get("ç·æ¥é™¢æ•°_å‰å¹´",0): d["ç·æ¥é™¢æ•°å¢—æ¸›ç‡%"]=((d["ç·æ¥é™¢æ•°_ä»Šå¹´"]-d["ç·æ¥é™¢æ•°_å‰å¹´"])/d["ç·æ¥é™¢æ•°_å‰å¹´"]*100).round(1)
    if d.get("LTV_å‰å¹´",0): d["LTVå¢—æ¸›ç‡%"]=((d["LTV_ä»Šå¹´"]-d["LTV_å‰å¹´"])/d["LTV_å‰å¹´"]*100).round(1)
    rows.append(d)
comp_disp = pd.concat([comp, pd.DataFrame(rows)], ignore_index=True)

st.subheader(f"ğŸ“Š å…¨åº—èˆ—ã‚µãƒãƒªãƒ¼ï¼ˆ{latest}å¹´ vs {prev}å¹´ï¼‰")
show_cols=["åº—èˆ—å","æœˆ","ç·å£²ä¸Š_å‰å¹´","ç·å£²ä¸Š_ä»Šå¹´","ç·å£²ä¸Šå¢—æ¸›ç‡%","ç·æ¥é™¢æ•°_å‰å¹´","ç·æ¥é™¢æ•°_ä»Šå¹´","ç·æ¥é™¢æ•°å¢—æ¸›ç‡%","LTV_å‰å¹´","LTV_ä»Šå¹´","LTVå¢—æ¸›ç‡%"]
st.dataframe(comp_disp[show_cols], use_container_width=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 7. åº—èˆ—åˆ¥ãƒ“ãƒ¥ãƒ¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

store = st.selectbox("ğŸ” åº—èˆ—ã‚’é¸æŠ", sorted(comp["åº—èˆ—å"].unique()))
st.markdown("---"); st.header(f"ğŸª {store} ã®è©³ç´°")
ss = comp[comp["åº—èˆ—å"]==store].sort_values("æœˆ")

# KPI
sum_row = ss[["ç·å£²ä¸Š_å‰å¹´","ç·å£²ä¸Š_ä»Šå¹´","ç·æ¥é™¢æ•°_å‰å¹´","ç·æ¥é™¢æ•°_ä»Šå¹´"]].sum()
c1,c2=st.columns(2)
c1.metric("å£²ä¸Š å‰å¹´æ¯”(ç´¯è¨ˆ)", f"{((sum_row['ç·å£²ä¸Š_ä»Šå¹´']-sum_row['ç·å£²ä¸Š_å‰å¹´'])/sum_row['ç·å£²ä¸Š_å‰å¹´']*100).round(1)} %")
c2.metric("æ¥é™¢æ•° å‰å¹´æ¯”(ç´¯è¨ˆ)", f"{((sum_row['ç·æ¥é™¢æ•°_ä»Šå¹´']-sum_row['ç·æ¥é™¢æ•°_å‰å¹´'])/sum_row['ç·æ¥é™¢æ•°_å‰å¹´']*100).round(1)} %")

c3,c4=st.columns(2)
c3.metric("å£²ä¸Š (ä»Šå¹´)", f"{int(sum_row['ç·å£²ä¸Š_ä»Šå¹´']):,} å††")
c4.metric("æ¥é™¢æ•° (ä»Šå¹´)", f"{int(sum_row['ç·æ¥é™¢æ•°_ä»Šå¹´']):,} äºº")

ltv_cur = ltv_df.query("åº—èˆ—å == @store & å¹´ == @latest")['LTV'].mean()
ltv_prev_mean = ltv_df.query("åº—èˆ—å == @store & å¹´ == @prev")['LTV'].mean()
if not math.isnan(ltv_cur):
    c5,c6=st.columns(2)
    c5.metric("LTV (ä»Šå¹´)", f"{ltv_cur:,.0f} å††")
    if ltv_prev_mean and not math.isnan(ltv_prev_mean):
        c6.metric("LTV å‰å¹´æ¯”", f"{((ltv_cur-ltv_prev_mean)/ltv_prev_mean*100).round(1):+.1f} %")

# æœˆåˆ¥è£œå®Œ
full_m=pd.DataFrame({"æœˆ":range(1,13)})
ss_full=full_m.merge(ss,on="æœˆ",how="left").fillna(0)
mask=(ss_full['ç·å£²ä¸Š_å‰å¹´']!=0)|(ss_full['ç·å£²ä¸Š_ä»Šå¹´']!=0)
ss_full=ss_full[mask]

# å£²ä¸Š & æ¥é™¢æ•°ã‚°ãƒ©ãƒ•
for label, cols, title, ytitle in [
    ("å£²ä¸Š", ["ç·å£²ä¸Š_å‰å¹´","ç·å£²ä¸Š_ä»Šå¹´"], "æœˆåˆ¥ç·å£²ä¸Š", "é‡‘é¡ (ä¸‡å††)"),
    ("æ¥é™¢æ•°", ["ç·æ¥é™¢æ•°_å‰å¹´","ç·æ¥é™¢æ•°_ä»Šå¹´"], "æœˆåˆ¥æ¥é™¢æ•°", "äººæ•°")]:
    df_plot=ss_full.melt(id_vars="æœˆ", value_vars=cols, var_name="å¹´åº¦", value_name=label)
    df_plot=df_plot.replace({cols[0]:prev, cols[1]:latest})
    if label=="å£²ä¸Š": df_plot[label]/=10000
    df_plot[["æœˆ","å¹´åº¦"]]=df_plot[["æœˆ","å¹´åº¦"]].astype(str)
    chart=(alt.Chart(df_plot).mark_bar().encode(
        x=alt.X("æœˆ:N",axis=alt.Axis(labelAngle=0)),
        y=alt.Y(f"{label}:Q", title=ytitle),
        xOffset="å¹´åº¦:N", color="å¹´åº¦:N", tooltip=["å¹´åº¦","æœˆ",label]
    ).properties(width=400,height=300,title=f"{store} {title}ï¼ˆå‰å¹´ vs ä»Šå¹´ï¼‰"))
    st.altair_chart(chart,use_container_width=True)

# æ¥åº—å‹•æ©Ÿ
if not reason_df.empty:
    rs=reason_df.query("åº—èˆ—å == @store & å¹´ == @latest").groupby("ã‚«ãƒ†ã‚´ãƒª",as_index=False)["ä»¶æ•°"].sum()
    if not rs.empty:
        rs["å‰²åˆ%"]=(rs["ä»¶æ•°"] / rs["ä»¶æ•°"].sum()*100).round(1)
        chart=alt.Chart(rs).mark_bar().encode(y=alt.Y("ã‚«ãƒ†ã‚´ãƒª:N",sort="-x"),x="ä»¶æ•°:Q",tooltip=["ã‚«ãƒ†ã‚´ãƒª","ä»¶æ•°","å‰²åˆ%"]).properties(width=350,height=250,title="æ¥åº—å‹•æ©Ÿ")
        st.altair_chart(chart, use_container_width=True)
        with st.expander("ğŸ“„ æ¥åº—å‹•æ©Ÿ æ˜ç´°"):
            st.dataframe(rs, use_container_width=True)

# ç”·å¥³æ¯”ç‡
if not gender_df.empty:
    gd=gender_df.query("åº—èˆ—å == @store & å¹´ == @latest").groupby("ã‚«ãƒ†ã‚´ãƒª",as_index=False)["ä»¶æ•°"].sum()
    if not gd.empty:
        gd["å‰²åˆ%"]=(gd["ä»¶æ•°"] / gd["ä»¶æ•°"].sum()*100).round(1)
        chart=alt.Chart(gd).mark_bar().encode(x=alt.X("ã‚«ãƒ†ã‚´ãƒª:N"),y="ä»¶æ•°:Q",tooltip=["ã‚«ãƒ†ã‚´ãƒª","ä»¶æ•°","å‰²åˆ%"],color="ã‚«ãƒ†ã‚´ãƒª:N").properties(width=350,height=250,title="ç”·å¥³æ¯”ç‡")
        st.altair_chart(chart, use_container_width=True)
        with st.expander("ğŸ“„ ç”·å¥³æ¯”ç‡ æ˜ç´°"):
            st.dataframe(gd, use_container_width=True)

# å¹´é½¢æ¯”ç‡
if not age_df.empty:
    ad=age_df.query("åº—èˆ—å == @store & å¹´ == @latest").groupby("ã‚«ãƒ†ã‚´ãƒª",as_index=False)["ä»¶æ•°"].sum()
    if not ad.empty:
        ad["å‰²åˆ%"]=(ad["ä»¶æ•°"] / ad["ä»¶æ•°"].sum()*100).round(1)
        chart=alt.Chart(ad).mark_bar().encode(y=alt.Y("ã‚«ãƒ†ã‚´ãƒª:N",sort="-x"),x="ä»¶æ•°:Q",tooltip=["ã‚«ãƒ†ã‚´ãƒª","ä»¶æ•°","å‰²åˆ%"]).properties(width=350,height=300,title="å¹´é½¢æ¯”ç‡")
        st.altair_chart(chart, use_container_width=True)
        with st.expander("ğŸ“„ å¹´é½¢æ¯”ç‡ æ˜ç´°"):
            st.dataframe(ad, use_container_width=True)

# å…ƒãƒ‡ãƒ¼ã‚¿
with st.expander("ğŸ“„ æœˆåˆ¥æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ï¼ˆåº—èˆ—ï¼‰"):
    st.dataframe(ss_full, use_container_width=True)
